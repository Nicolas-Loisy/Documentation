# Guide Complet : D√©marrer un Projet Machine Learning

## üìã Table des Mati√®res

1. [Checklist Compl√®te d'un Projet ML](#checklist-compl√®te-dun-projet-ml)
2. [Phase 1 : Compr√©hension du Probl√®me](#phase-1--compr√©hension-du-probl√®me)
3. [Phase 2 : Collecte et Exploration des Donn√©es](#phase-2--collecte-et-exploration-des-donn√©es)
4. [Phase 3 : Pr√©paration des Donn√©es](#phase-3--pr√©paration-des-donn√©es)
5. [Phase 4 : Mod√©lisation](#phase-4--mod√©lisation)
6. [Phase 5 : √âvaluation](#phase-5--√©valuation)
7. [Phase 6 : D√©ploiement](#phase-6--d√©ploiement)
8. [Questions Critiques √† se Poser](#questions-critiques-√†-se-poser)
9. [Templates de Documentation](#templates-de-documentation)

---

## Checklist Compl√®te d'un Projet ML

### ‚úÖ Phase 1 : Compr√©hension du Probl√®me

- [ ] D√©finir la probl√©matique m√©tier clairement
- [ ] Identifier les objectifs mesurables
- [ ] D√©terminer le type de probl√®me ML
- [ ] √âvaluer la faisabilit√© du projet
- [ ] D√©finir les crit√®res de succ√®s
- [ ] Identifier les contraintes (temps, budget, ressources)
- [ ] Comprendre l'impact business

### ‚úÖ Phase 2 : Collecte et Exploration des Donn√©es

- [ ] Identifier les sources de donn√©es disponibles
- [ ] Collecter les donn√©es n√©cessaires
- [ ] V√©rifier la qualit√© des donn√©es
- [ ] Analyser les statistiques descriptives
- [ ] Visualiser les distributions
- [ ] Identifier les valeurs manquantes
- [ ] D√©tecter les outliers
- [ ] Analyser les corr√©lations entre variables

### ‚úÖ Phase 3 : Pr√©paration des Donn√©es

- [ ] Traiter les valeurs manquantes
- [ ] G√©rer les outliers
- [ ] Encoder les variables cat√©gorielles
- [ ] Normaliser/standardiser les variables num√©riques
- [ ] Cr√©er de nouvelles features (feature engineering)
- [ ] S√©lectionner les features pertinentes
- [ ] Diviser les donn√©es (train/validation/test)
- [ ] G√©rer le d√©s√©quilibre des classes (si n√©cessaire)

### ‚úÖ Phase 4 : Mod√©lisation

- [ ] Choisir les mod√®les candidats
- [ ] D√©finir la baseline
- [ ] Entra√Æner les mod√®les
- [ ] Optimiser les hyperparam√®tres
- [ ] Valider avec cross-validation
- [ ] Comparer les performances
- [ ] S√©lectionner le meilleur mod√®le
- [ ] Analyser les erreurs

### ‚úÖ Phase 5 : √âvaluation

- [ ] √âvaluer sur le test set
- [ ] Calculer les m√©triques appropri√©es
- [ ] Analyser la matrice de confusion (classification)
- [ ] V√©rifier l'overfitting/underfitting
- [ ] Tester sur cas limites
- [ ] Interpr√©ter les pr√©dictions
- [ ] Documenter les r√©sultats

### ‚úÖ Phase 6 : D√©ploiement

- [ ] Pr√©parer le mod√®le pour production
- [ ] Cr√©er une API ou interface
- [ ] Mettre en place le monitoring
- [ ] Tester en environnement r√©el
- [ ] Former les utilisateurs
- [ ] Planifier la maintenance
- [ ] Pr√©voir le retraining

---

## Phase 1 : Compr√©hension du Probl√®me

### Questions Essentielles

#### 1. Quelle est la probl√©matique m√©tier ?

**Template de probl√©matique :**

```
Contexte : [D√©crire la situation actuelle]
Probl√®me : [Quel probl√®me cherche-t-on √† r√©soudre ?]
Impact : [Quelles sont les cons√©quences du probl√®me ?]
Solution envisag√©e : [Comment le ML peut-il aider ?]
```

**Exemple :**

```
Contexte : Une banque re√ßoit des milliers de demandes de cr√©dit par jour
Probl√®me : Le processus d'√©valuation manuel est lent et co√ªteux
Impact : Perte de clients, co√ªts op√©rationnels √©lev√©s
Solution envisag√©e : Syst√®me automatis√© de pr√©diction de d√©faut de paiement
```

#### 2. Quel est le type de probl√®me ML ?

| Type                            | Description                | Exemples                                               |
| ------------------------------- | -------------------------- | ------------------------------------------------------ |
| **Classification binaire**      | 2 classes                  | Spam/Non-spam, Fraude/L√©gitime                         |
| **Classification multi-classe** | >2 classes                 | Reconnaissance de chiffres, Cat√©gorisation de produits |
| **R√©gression**                  | Pr√©diction valeur continue | Prix immobilier, Temp√©rature                           |
| **Clustering**                  | Groupement sans labels     | Segmentation client                                    |
| **D√©tection d'anomalies**       | Identifier les outliers    | Fraude, D√©fauts industriels                            |
| **S√©ries temporelles**          | Pr√©diction temporelle      | Pr√©vision des ventes, Prix boursiers                   |
| **NLP**                         | Traitement du langage      | Analyse de sentiment, Traduction                       |
| **Vision**                      | Traitement d'images        | D√©tection d'objets, Classification d'images            |

#### 3. Quels sont les objectifs mesurables ?

**Template d'objectifs :**

```
Objectif principal : [M√©trique cible]
  - Actuel : [Valeur baseline]
  - Cible : [Valeur √† atteindre]
  - D√©lai : [Quand ?]

Objectifs secondaires :
  - [Autre m√©trique 1]
  - [Autre m√©trique 2]
```

**Exemple :**

```
Objectif principal : R√©duire le taux de d√©faut de paiement
  - Actuel : 15% des cr√©dits accord√©s
  - Cible : <8% des cr√©dits accord√©s
  - D√©lai : 6 mois

Objectifs secondaires :
  - R√©duire le temps de traitement de 5 jours √† 1 heure
  - Maintenir un taux d'approbation >70%
```

#### 4. Quelles sont les contraintes ?

**Contraintes √† identifier :**

| Type                 | Questions                                                       |
| -------------------- | --------------------------------------------------------------- |
| **Temps**            | Quelle est la deadline ? Temps d'inf√©rence acceptable ?         |
| **Budget**           | Ressources de calcul disponibles ? Budget cloud ?               |
| **Donn√©es**          | Quantit√© de donn√©es disponibles ? Qualit√© ? Labels ?            |
| **Interpr√©tabilit√©** | Le mod√®le doit-il √™tre explicable ? (m√©dical, finance)          |
| **Pr√©cision**        | Quelle pr√©cision minimale ? Quel type d'erreur est acceptable ? |
| **D√©ploiement**      | Edge device ? Cloud ? On-premise ?                              |
| **L√©gal**            | RGPD ? Autres r√©glementations ?                                 |

#### 5. D√©finir les crit√®res de succ√®s

**Crit√®res techniques :**

- M√©triques de performance (accuracy, F1, RMSE, etc.)
- Temps d'inf√©rence
- Taille du mod√®le
- Robustesse

**Crit√®res business :**

- ROI attendu
- R√©duction des co√ªts
- Am√©lioration de l'exp√©rience utilisateur
- Gain de productivit√©

---

## Phase 2 : Collecte et Exploration des Donn√©es

### Questions sur les Donn√©es

#### 1. Quelles donn√©es sont disponibles ?

**Checklist des donn√©es :**

```python
# Template d'inventaire des donn√©es
donnees_disponibles = {
    'source_1': {
        'type': 'Base de donn√©es SQL',
        'volume': '1M lignes',
        'periode': '2020-2024',
        'format': 'Structur√©',
        'qualite': 'Bonne',
        'acces': 'API',
        'cout': 'Gratuit'
    },
    'source_2': {
        'type': 'Fichiers CSV',
        'volume': '500K lignes',
        'periode': '2022-2024',
        'format': 'Semi-structur√©',
        'qualite': 'Moyenne (valeurs manquantes)',
        'acces': 'FTP',
        'cout': 'Gratuit'
    }
}
```

#### 2. Quel est le type de donn√©es ?

| Type                        | Exemples                           | Pr√©paration                            |
| --------------------------- | ---------------------------------- | -------------------------------------- |
| **Num√©riques continues**    | Prix, temp√©rature, √¢ge             | Normalisation, standardisation         |
| **Num√©riques discr√®tes**    | Nombre de produits, compteurs      | Binning possible                       |
| **Cat√©gorielles ordinales** | Niveau d'√©ducation, taille (S/M/L) | Ordinal encoding                       |
| **Cat√©gorielles nominales** | Couleur, ville, cat√©gorie          | One-hot encoding, target encoding      |
| **Temporelles**             | Date, heure, timestamp             | Feature engineering (jour, mois, etc.) |
| **Texte**                   | Avis, descriptions                 | TF-IDF, embeddings                     |
| **Images**                  | Photos, scans                      | Normalisation, augmentation            |
| **Audio**                   | Voix, sons                         | Spectrogrammes, MFCC                   |

#### 3. Analyse Exploratoire des Donn√©es (EDA)

**Script EDA Standard :**

```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

def analyse_exploratoire(df):
    """
    Analyse exploratoire compl√®te d'un DataFrame
    """
    print("="*80)
    print("1. INFORMATIONS G√âN√âRALES")
    print("="*80)
    print(f"Dimensions : {df.shape[0]} lignes √ó {df.shape[1]} colonnes")
    print(f"\nM√©moire utilis√©e : {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB")

    print("\n" + "="*80)
    print("2. TYPES DE DONN√âES")
    print("="*80)
    print(df.dtypes.value_counts())

    print("\n" + "="*80)
    print("3. VALEURS MANQUANTES")
    print("="*80)
    missing = df.isnull().sum()
    missing_pct = 100 * missing / len(df)
    missing_table = pd.DataFrame({
        'Manquantes': missing,
        'Pourcentage': missing_pct
    })
    print(missing_table[missing_table['Manquantes'] > 0].sort_values('Pourcentage', ascending=False))

    print("\n" + "="*80)
    print("4. STATISTIQUES DESCRIPTIVES")
    print("="*80)
    print(df.describe())

    print("\n" + "="*80)
    print("5. DOUBLONS")
    print("="*80)
    duplicates = df.duplicated().sum()
    print(f"Nombre de doublons : {duplicates} ({100*duplicates/len(df):.2f}%)")

    print("\n" + "="*80)
    print("6. CARDINALIT√â DES VARIABLES CAT√âGORIELLES")
    print("="*80)
    cat_cols = df.select_dtypes(include=['object', 'category']).columns
    for col in cat_cols:
        print(f"{col}: {df[col].nunique()} valeurs uniques")
        if df[col].nunique() <= 10:
            print(df[col].value_counts())
        print()

    # Visualisations
    print("\n" + "="*80)
    print("7. VISUALISATIONS")
    print("="*80)

    # Distribution des variables num√©riques
    num_cols = df.select_dtypes(include=[np.number]).columns
    if len(num_cols) > 0:
        fig, axes = plt.subplots(len(num_cols), 2, figsize=(15, 5*len(num_cols)))
        if len(num_cols) == 1:
            axes = axes.reshape(1, -1)

        for idx, col in enumerate(num_cols):
            # Histogramme
            axes[idx, 0].hist(df[col].dropna(), bins=30, edgecolor='black')
            axes[idx, 0].set_title(f'Distribution de {col}')
            axes[idx, 0].set_xlabel(col)
            axes[idx, 0].set_ylabel('Fr√©quence')

            # Boxplot
            axes[idx, 1].boxplot(df[col].dropna())
            axes[idx, 1].set_title(f'Boxplot de {col}')
            axes[idx, 1].set_ylabel(col)

        plt.tight_layout()
        plt.show()

    # Matrice de corr√©lation
    if len(num_cols) > 1:
        plt.figure(figsize=(12, 10))
        correlation = df[num_cols].corr()
        sns.heatmap(correlation, annot=True, fmt='.2f', cmap='coolwarm',
                    square=True, linewidths=0.5)
        plt.title('Matrice de Corr√©lation')
        plt.tight_layout()
        plt.show()

    return {
        'shape': df.shape,
        'missing': missing_table[missing_table['Manquantes'] > 0],
        'duplicates': duplicates,
        'dtypes': df.dtypes
    }

# Utilisation
# resultats = analyse_exploratoire(df)
```

#### 4. Questions sur la Qualit√© des Donn√©es

**Checklist qualit√© :**

- [ ] **Compl√©tude** : Taux de valeurs manquantes acceptable ?
- [ ] **Coh√©rence** : Les valeurs sont-elles coh√©rentes ? (ex: √¢ge n√©gatif)
- [ ] **Pr√©cision** : Les donn√©es sont-elles exactes ?
- [ ] **Actualit√©** : Les donn√©es sont-elles √† jour ?
- [ ] **Unicit√©** : Y a-t-il des doublons ?
- [ ] **Repr√©sentativit√©** : Les donn√©es refl√®tent-elles la population cible ?
- [ ] **√âquilibre** : Les classes sont-elles √©quilibr√©es (classification) ?

---

## Phase 3 : Pr√©paration des Donn√©es

### 1. Traitement des Valeurs Manquantes

#### Strat√©gies selon le contexte

```python
# D√©cision : Comment traiter les valeurs manquantes ?

def strategie_valeurs_manquantes(df, col):
    """
    Guide de d√©cision pour valeurs manquantes
    """
    missing_pct = df[col].isnull().sum() / len(df) * 100

    print(f"Colonne : {col}")
    print(f"Valeurs manquantes : {missing_pct:.2f}%")

    if missing_pct > 50:
        print("‚Üí RECOMMANDATION : Supprimer la colonne (trop de valeurs manquantes)")
    elif missing_pct > 20:
        print("‚Üí RECOMMANDATION : Imputation avanc√©e ou cr√©er feature 'is_missing'")
    else:
        if df[col].dtype in ['int64', 'float64']:
            print("‚Üí OPTIONS :")
            print("  - Imputation par la moyenne (si distribution normale)")
            print("  - Imputation par la m√©diane (si outliers)")
            print("  - Imputation par r√©gression/KNN (si corr√©l√© √† autres features)")
        else:
            print("‚Üí OPTIONS :")
            print("  - Imputation par le mode")
            print("  - Imputation par 'Unknown' / 'Missing'")
            print("  - Imputation par mod√®le (classification)")
    print()

# M√©thodes d'imputation
from sklearn.impute import SimpleImputer, KNNImputer

# 1. Imputation simple
imputer_mean = SimpleImputer(strategy='mean')  # moyenne
imputer_median = SimpleImputer(strategy='median')  # m√©diane
imputer_mode = SimpleImputer(strategy='most_frequent')  # mode

# 2. Imputation KNN
imputer_knn = KNNImputer(n_neighbors=5)

# 3. Imputation par r√©gression
from sklearn.experimental import enable_iterative_imputer
from sklearn.impute import IterativeImputer
imputer_iter = IterativeImputer(max_iter=10, random_state=42)
```

### 2. Gestion des Outliers

#### D√©tection

```python
def detecter_outliers(df, col):
    """
    D√©tecte les outliers par plusieurs m√©thodes
    """
    print(f"Analyse des outliers pour : {col}")
    print("="*60)

    # M√©thode 1 : IQR
    Q1 = df[col].quantile(0.25)
    Q3 = df[col].quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR

    outliers_iqr = df[(df[col] < lower_bound) | (df[col] > upper_bound)]
    print(f"M√©thode IQR : {len(outliers_iqr)} outliers ({len(outliers_iqr)/len(df)*100:.2f}%)")
    print(f"  Bornes : [{lower_bound:.2f}, {upper_bound:.2f}]")

    # M√©thode 2 : Z-score
    from scipy import stats
    z_scores = np.abs(stats.zscore(df[col].dropna()))
    outliers_z = df[np.abs(z_scores) > 3]
    print(f"M√©thode Z-score (>3) : {len(outliers_z)} outliers ({len(outliers_z)/len(df)*100:.2f}%)")

    # M√©thode 3 : Isolation Forest
    from sklearn.ensemble import IsolationForest
    iso = IsolationForest(contamination=0.1, random_state=42)
    outliers_iso = iso.fit_predict(df[[col]])
    n_outliers_iso = (outliers_iso == -1).sum()
    print(f"M√©thode Isolation Forest : {n_outliers_iso} outliers ({n_outliers_iso/len(df)*100:.2f}%)")

    # Visualisation
    fig, axes = plt.subplots(1, 2, figsize=(14, 5))

    # Boxplot
    axes[0].boxplot(df[col].dropna())
    axes[0].set_title(f'Boxplot - {col}')
    axes[0].axhline(lower_bound, color='r', linestyle='--', label='Borne IQR inf')
    axes[0].axhline(upper_bound, color='r', linestyle='--', label='Borne IQR sup')
    axes[0].legend()

    # Distribution
    axes[1].hist(df[col].dropna(), bins=50, edgecolor='black')
    axes[1].axvline(lower_bound, color='r', linestyle='--')
    axes[1].axvline(upper_bound, color='r', linestyle='--')
    axes[1].set_title(f'Distribution - {col}')
    axes[1].set_xlabel(col)

    plt.tight_layout()
    plt.show()

    return {
        'iqr': outliers_iqr.index,
        'z_score': outliers_z.index,
        'isolation_forest': df.index[outliers_iso == -1]
    }

# Strat√©gies de traitement
def traiter_outliers(df, col, method='cap'):
    """
    Traite les outliers selon la m√©thode choisie

    Methods:
    - 'remove': Supprimer les outliers
    - 'cap': Capping (remplacer par les bornes)
    - 'log': Transformation logarithmique
    - 'winsorize': Winsorisation
    """
    if method == 'remove':
        # IQR
        Q1 = df[col].quantile(0.25)
        Q3 = df[col].quantile(0.75)
        IQR = Q3 - Q1
        lower = Q1 - 1.5 * IQR
        upper = Q3 + 1.5 * IQR
        df = df[(df[col] >= lower) & (df[col] <= upper)]

    elif method == 'cap':
        # Capping
        Q1 = df[col].quantile(0.25)
        Q3 = df[col].quantile(0.75)
        IQR = Q3 - Q1
        lower = Q1 - 1.5 * IQR
        upper = Q3 + 1.5 * IQR
        df[col] = df[col].clip(lower, upper)

    elif method == 'log':
        # Log transformation
        df[col] = np.log1p(df[col])

    elif method == 'winsorize':
        # Winsorisation
        from scipy.stats.mstats import winsorize
        df[col] = winsorize(df[col], limits=[0.05, 0.05])

    return df
```

### 3. Feature Engineering

#### Questions sur les Features

```python
# Guide de Feature Engineering

"""
QUESTIONS √Ä SE POSER :

1. Combinaisons de features
   - Peut-on cr√©er des ratios ? (ex: prix/m¬≤)
   - Peut-on cr√©er des diff√©rences ? (ex: √¢ge_max - √¢ge_min)
   - Peut-on cr√©er des produits ? (ex: longueur √ó largeur)

2. Extraction d'information
   - Dates : jour, mois, ann√©e, jour de semaine, trimestre, est_weekend
   - Texte : longueur, nombre de mots, sentiment, entit√©s
   - Cat√©gories : fr√©quence, regroupement

3. Transformations
   - Log, sqrt, carr√© (pour normaliser distributions)
   - Binning (discr√©tisation)
   - Polynomiales (pour capturer non-lin√©arit√©)

4. Agr√©gations
   - Groupby + statistiques (mean, sum, count, etc.)
   - Rolling windows (s√©ries temporelles)

5. Encoding
   - One-hot encoding (peu de cat√©gories)
   - Target encoding (beaucoup de cat√©gories)
   - Frequency encoding
   - Embedding (Deep Learning)
"""

# Exemples de Feature Engineering

def feature_engineering_dates(df, date_col):
    """
    Extrait des features d'une colonne date
    """
    df[date_col] = pd.to_datetime(df[date_col])

    df[f'{date_col}_year'] = df[date_col].dt.year
    df[f'{date_col}_month'] = df[date_col].dt.month
    df[f'{date_col}_day'] = df[date_col].dt.day
    df[f'{date_col}_dayofweek'] = df[date_col].dt.dayofweek
    df[f'{date_col}_quarter'] = df[date_col].dt.quarter
    df[f'{date_col}_is_weekend'] = df[date_col].dt.dayofweek.isin([5, 6]).astype(int)
    df[f'{date_col}_is_month_start'] = df[date_col].dt.is_month_start.astype(int)
    df[f'{date_col}_is_month_end'] = df[date_col].dt.is_month_end.astype(int)

    return df

def feature_engineering_agregations(df, group_col, agg_col):
    """
    Cr√©e des features d'agr√©gation
    """
    agg_features = df.groupby(group_col)[agg_col].agg([
        'mean', 'median', 'std', 'min', 'max', 'sum', 'count'
    ]).reset_index()

    agg_features.columns = [group_col] + [f'{agg_col}_{stat}_by_{group_col}'
                                          for stat in ['mean', 'median', 'std', 'min', 'max', 'sum', 'count']]

    df = df.merge(agg_features, on=group_col, how='left')
    return df

def feature_engineering_interactions(df, cols):
    """
    Cr√©e des interactions entre features
    """
    for i, col1 in enumerate(cols):
        for col2 in cols[i+1:]:
            # Produit
            df[f'{col1}_x_{col2}'] = df[col1] * df[col2]
            # Ratio
            df[f'{col1}_div_{col2}'] = df[col1] / (df[col2] + 1e-5)
            # Diff√©rence
            df[f'{col1}_minus_{col2}'] = df[col1] - df[col2]

    return df
```

### 4. Encodage des Variables Cat√©gorielles

```python
from sklearn.preprocessing import LabelEncoder, OneHotEncoder
from category_encoders import TargetEncoder

def guide_encodage(df, col, target=None):
    """
    Guide pour choisir la m√©thode d'encodage
    """
    n_unique = df[col].nunique()

    print(f"Colonne : {col}")
    print(f"Nombre de cat√©gories uniques : {n_unique}")

    if n_unique == 2:
        print("‚Üí RECOMMANDATION : Label Encoding (2 cat√©gories)")
        print("  from sklearn.preprocessing import LabelEncoder")
    elif n_unique <= 10:
        print("‚Üí RECOMMANDATION : One-Hot Encoding")
        print("  pd.get_dummies() ou OneHotEncoder")
    elif n_unique <= 50:
        print("‚Üí RECOMMANDATION : Target Encoding ou Frequency Encoding")
        print("  from category_encoders import TargetEncoder")
    else:
        print("‚Üí RECOMMANDATION : Target Encoding, Hashing ou Embedding")
        print("  Attention au overfitting avec Target Encoding")
    print()

# 1. Label Encoding (ordinale ou binaire)
le = LabelEncoder()
df['col_encoded'] = le.fit_transform(df['col'])

# 2. One-Hot Encoding
df_encoded = pd.get_dummies(df, columns=['col'], drop_first=True)

# 3. Target Encoding
te = TargetEncoder()
df['col_encoded'] = te.fit_transform(df['col'], df['target'])

# 4. Frequency Encoding
freq = df['col'].value_counts(normalize=True)
df['col_encoded'] = df['col'].map(freq)
```

### 5. Normalisation et Standardisation

```python
from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler

def guide_normalisation(df, col):
    """
    Guide pour choisir la m√©thode de normalisation
    """
    print(f"Analyse de {col}")
    print("="*60)

    # Statistiques
    mean = df[col].mean()
    median = df[col].median()
    std = df[col].std()
    skew = df[col].skew()

    print(f"Moyenne : {mean:.2f}")
    print(f"M√©diane : {median:.2f}")
    print(f"√âcart-type : {std:.2f}")
    print(f"Skewness : {skew:.2f}")

    # Recommandation
    if abs(skew) < 0.5:
        print("\n‚Üí Distribution proche de la normale")
        print("  RECOMMANDATION : StandardScaler (Z-score)")
    elif abs(skew) >= 0.5:
        print("\n‚Üí Distribution asym√©trique")
        print("  RECOMMANDATION : RobustScaler (r√©sistant aux outliers)")

    print("\n‚Üí Pour borner les valeurs dans [0,1] : MinMaxScaler")
    print("‚Üí Pour r√©seaux de neurones : Normalisation [0,1] ou [-1,1] recommand√©e")
    print()

# M√©thodes de normalisation

# 1. Standardisation (Z-score) : moyenne=0, √©cart-type=1
scaler = StandardScaler()
df_scaled = scaler.fit_transform(df[num_cols])

# 2. Min-Max : valeurs dans [0, 1]
scaler = MinMaxScaler()
df_scaled = scaler.fit_transform(df[num_cols])

# 3. Robust : r√©sistant aux outliers
scaler = RobustScaler()
df_scaled = scaler.fit_transform(df[num_cols])
```

---

## Phase 4 : Mod√©lisation

### Questions pour Choisir un Mod√®le

#### Arbre de D√©cision

```
1. Quel est le type de probl√®me ?
   ‚îú‚îÄ Classification
   ‚îÇ  ‚îú‚îÄ Lin√©airement s√©parable ? ‚Üí Logistic Regression, SVM lin√©aire
   ‚îÇ  ‚îú‚îÄ Non-lin√©aire ?
   ‚îÇ  ‚îÇ  ‚îú‚îÄ Petites donn√©es (<10k) ‚Üí SVM (kernel RBF), Decision Tree
   ‚îÇ  ‚îÇ  ‚îú‚îÄ Moyennes donn√©es (10k-100k) ‚Üí Random Forest, XGBoost
   ‚îÇ  ‚îÇ  ‚îî‚îÄ Grandes donn√©es (>100k) ‚Üí XGBoost, LightGBM, Deep Learning
   ‚îÇ  ‚îî‚îÄ Interpr√©tabilit√© requise ? ‚Üí Logistic Regression, Decision Tree
   ‚îÇ
   ‚îú‚îÄ R√©gression
   ‚îÇ  ‚îú‚îÄ Relation lin√©aire ? ‚Üí Linear Regression, Ridge, Lasso
   ‚îÇ  ‚îú‚îÄ Non-lin√©aire ?
   ‚îÇ  ‚îÇ  ‚îú‚îÄ Petites donn√©es ‚Üí SVR, Decision Tree
   ‚îÇ  ‚îÇ  ‚îú‚îÄ Moyennes donn√©es ‚Üí Random Forest, XGBoost
   ‚îÇ  ‚îÇ  ‚îî‚îÄ Grandes donn√©es ‚Üí XGBoost, LightGBM, Deep Learning
   ‚îÇ  ‚îî‚îÄ Interpr√©tabilit√© ? ‚Üí Linear Regression, Decision Tree
   ‚îÇ
   ‚îú‚îÄ Clustering
   ‚îÇ  ‚îú‚îÄ Nombre de clusters connu ? ‚Üí K-Means
   ‚îÇ  ‚îú‚îÄ Clusters de formes arbitraires ? ‚Üí DBSCAN, HDBSCAN
   ‚îÇ  ‚îî‚îÄ Hi√©rarchie importante ? ‚Üí Hierarchical Clustering
   ‚îÇ
   ‚îú‚îÄ R√©duction de dimensionnalit√©
   ‚îÇ  ‚îú‚îÄ Lin√©aire + compression ‚Üí PCA
   ‚îÇ  ‚îú‚îÄ Visualisation ‚Üí t-SNE, UMAP
   ‚îÇ  ‚îî‚îÄ Non-lin√©aire + g√©n√©ration ‚Üí Autoencoder
   ‚îÇ
   ‚îî‚îÄ D√©tection d'anomalies
      ‚îú‚îÄ Isolation ‚Üí Isolation Forest
      ‚îú‚îÄ Fronti√®re distribution ‚Üí One-Class SVM
      ‚îî‚îÄ Reconstruction ‚Üí Autoencoder

2. Quelle est la taille des donn√©es ?
   - <1k : Simple models (Decision Tree, Logistic Regression)
   - 1k-100k : Ensemble methods (Random Forest, XGBoost)
   - >100k : Gradient Boosting, Deep Learning

3. Quel est le type de donn√©es ?
   - Tabulaires : XGBoost, Random Forest
   - Images : CNN (ResNet, EfficientNet)
   - Texte : Transformers (BERT), RNN
   - S√©ries temporelles : LSTM, GRU, Prophet

4. Contraintes de temps ?
   - Entra√Ænement rapide : Logistic Regression, Decision Tree
   - Inf√©rence rapide : Linear models, petits trees
   - Temps non contraint : Deep Learning, XGBoost avec tuning
```

### Workflow de Mod√©lisation

```python
from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV
from sklearn.metrics import accuracy_score, f1_score, mean_squared_error

# 1. Diviser les donn√©es
X_train, X_temp, y_train, y_temp = train_test_split(
    X, y, test_size=0.3, random_state=42, stratify=y  # stratify pour classification
)
X_val, X_test, y_val, y_test = train_test_split(
    X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp
)

print(f"Train: {len(X_train)} | Validation: {len(X_val)} | Test: {len(X_test)}")

# 2. D√©finir la baseline
from sklearn.dummy import DummyClassifier

baseline = DummyClassifier(strategy='most_frequent')
baseline.fit(X_train, y_train)
baseline_score = baseline.score(X_val, y_val)
print(f"Baseline Accuracy: {baseline_score:.4f}")

# 3. Tester plusieurs mod√®les
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier

models = {
    'Logistic Regression': LogisticRegression(max_iter=1000),
    'Decision Tree': DecisionTreeClassifier(random_state=42),
    'Random Forest': RandomForestClassifier(random_state=42, n_estimators=100),
    'XGBoost': XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss')
}

results = {}

for name, model in models.items():
    # Entra√Æner
    model.fit(X_train, y_train)

    # √âvaluer
    train_score = model.score(X_train, y_train)
    val_score = model.score(X_val, y_val)

    # Cross-validation
    cv_scores = cross_val_score(model, X_train, y_train, cv=5)

    results[name] = {
        'train_score': train_score,
        'val_score': val_score,
        'cv_mean': cv_scores.mean(),
        'cv_std': cv_scores.std()
    }

    print(f"\n{name}")
    print(f"  Train: {train_score:.4f}")
    print(f"  Val: {val_score:.4f}")
    print(f"  CV: {cv_scores.mean():.4f} (+/- {cv_scores.std():.4f})")
    print(f"  Overfitting: {train_score - val_score:.4f}")

# 4. S√©lectionner le meilleur mod√®le
best_model_name = max(results, key=lambda k: results[k]['val_score'])
print(f"\nüèÜ Meilleur mod√®le : {best_model_name}")

# 5. Optimiser les hyperparam√®tres
if best_model_name == 'XGBoost':
    param_grid = {
        'n_estimators': [100, 200, 300],
        'max_depth': [3, 5, 7],
        'learning_rate': [0.01, 0.1, 0.3],
        'subsample': [0.8, 1.0]
    }

    grid_search = GridSearchCV(
        XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss'),
        param_grid,
        cv=5,
        scoring='accuracy',
        n_jobs=-1,
        verbose=1
    )

    grid_search.fit(X_train, y_train)

    print(f"\nMeilleurs param√®tres : {grid_search.best_params_}")
    print(f"Meilleur score CV : {grid_search.best_score_:.4f}")

    best_model = grid_search.best_estimator_

# 6. √âvaluation finale sur test set
y_pred_test = best_model.predict(X_test)
test_score = accuracy_score(y_test, y_pred_test)
print(f"\nüìä Score final sur test set : {test_score:.4f}")
```

---

## Phase 5 : √âvaluation

### M√©triques selon le Type de Probl√®me

#### Classification

```python
from sklearn.metrics import (
    accuracy_score, precision_score, recall_score, f1_score,
    confusion_matrix, classification_report, roc_auc_score, roc_curve
)

def evaluation_classification(y_true, y_pred, y_proba=None):
    """
    √âvaluation compl√®te pour classification
    """
    print("="*80)
    print("√âVALUATION - CLASSIFICATION")
    print("="*80)

    # M√©triques de base
    acc = accuracy_score(y_true, y_pred)
    prec = precision_score(y_true, y_pred, average='weighted')
    rec = recall_score(y_true, y_pred, average='weighted')
    f1 = f1_score(y_true, y_pred, average='weighted')

    print(f"\nAccuracy  : {acc:.4f}")
    print(f"Precision : {prec:.4f}")
    print(f"Recall    : {rec:.4f}")
    print(f"F1-Score  : {f1:.4f}")

    # Matrice de confusion
    print("\nMatrice de Confusion :")
    cm = confusion_matrix(y_true, y_pred)
    print(cm)

    # Classification report
    print("\nClassification Report :")
    print(classification_report(y_true, y_pred))

    # ROC-AUC (si probabilit√©s disponibles)
    if y_proba is not None:
        if len(np.unique(y_true)) == 2:  # Binaire
            auc = roc_auc_score(y_true, y_proba[:, 1])
            print(f"\nROC-AUC : {auc:.4f}")

            # Courbe ROC
            fpr, tpr, _ = roc_curve(y_true, y_proba[:, 1])
            plt.figure(figsize=(8, 6))
            plt.plot(fpr, tpr, label=f'ROC (AUC = {auc:.4f})')
            plt.plot([0, 1], [0, 1], 'k--', label='Random')
            plt.xlabel('False Positive Rate')
            plt.ylabel('True Positive Rate')
            plt.title('Courbe ROC')
            plt.legend()
            plt.grid(True, alpha=0.3)
            plt.show()

    # Visualisation matrice de confusion
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)
    plt.xlabel('Pr√©diction')
    plt.ylabel('R√©alit√©')
    plt.title('Matrice de Confusion')
    plt.show()

# Utilisation
# evaluation_classification(y_test, y_pred, model.predict_proba(X_test))
```

**Guide de choix de m√©triques :**

| Contexte                                      | M√©trique Principale | Raison                          |
| --------------------------------------------- | ------------------- | ------------------------------- |
| **Classes √©quilibr√©es**                       | Accuracy            | Simple et suffisant             |
| **Classes d√©s√©quilibr√©es**                    | F1-Score, ROC-AUC   | Prend en compte le d√©s√©quilibre |
| **Co√ªt des faux n√©gatifs √©lev√©** (ex: cancer) | Recall              | Minimiser les cas manqu√©s       |
| **Co√ªt des faux positifs √©lev√©** (ex: spam)   | Precision           | Minimiser les fausses alarmes   |
| **Trade-off**                                 | F1-Score            | √âquilibre precision/recall      |
| **Ranking/probabilit√©s**                      | ROC-AUC             | √âvalue qualit√© des scores       |

#### R√©gression

```python
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

def evaluation_regression(y_true, y_pred):
    """
    √âvaluation compl√®te pour r√©gression
    """
    print("="*80)
    print("√âVALUATION - R√âGRESSION")
    print("="*80)

    # M√©triques
    mse = mean_squared_error(y_true, y_pred)
    rmse = np.sqrt(mse)
    mae = mean_absolute_error(y_true, y_pred)
    r2 = r2_score(y_true, y_pred)

    # MAPE (Mean Absolute Percentage Error)
    mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100

    print(f"\nMSE  : {mse:.4f}")
    print(f"RMSE : {rmse:.4f}")
    print(f"MAE  : {mae:.4f}")
    print(f"R¬≤   : {r2:.4f}")
    print(f"MAPE : {mape:.2f}%")

    # Interpr√©tation R¬≤
    if r2 > 0.9:
        print("  ‚Üí Excellent mod√®le")
    elif r2 > 0.7:
        print("  ‚Üí Bon mod√®le")
    elif r2 > 0.5:
        print("  ‚Üí Mod√®le acceptable")
    else:
        print("  ‚Üí Mod√®le faible")

    # Visualisations
    fig, axes = plt.subplots(1, 2, figsize=(14, 5))

    # Scatter plot : pr√©dictions vs r√©alit√©
    axes[0].scatter(y_true, y_pred, alpha=0.5, edgecolors='k')
    axes[0].plot([y_true.min(), y_true.max()],
                 [y_true.min(), y_true.max()],
                 'r--', lw=2, label='Pr√©diction parfaite')
    axes[0].set_xlabel('Valeur R√©elle')
    axes[0].set_ylabel('Pr√©diction')
    axes[0].set_title(f'Pr√©dictions vs R√©alit√© (R¬≤ = {r2:.4f})')
    axes[0].legend()
    axes[0].grid(True, alpha=0.3)

    # Distribution des r√©sidus
    residuals = y_true - y_pred
    axes[1].hist(residuals, bins=30, edgecolor='black')
    axes[1].axvline(0, color='r', linestyle='--', linewidth=2)
    axes[1].set_xlabel('R√©sidus')
    axes[1].set_ylabel('Fr√©quence')
    axes[1].set_title(f'Distribution des R√©sidus (MAE = {mae:.4f})')
    axes[1].grid(True, alpha=0.3)

    plt.tight_layout()
    plt.show()

# Utilisation
# evaluation_regression(y_test, y_pred)
```

**Guide de choix de m√©triques :**

| M√©trique | Caract√©ristiques                   | Usage                               |
| -------- | ---------------------------------- | ----------------------------------- |
| **MSE**  | P√©nalise fortement grandes erreurs | Quand grandes erreurs inacceptables |
| **RMSE** | M√™me unit√© que la cible            | Interpr√©tation facile               |
| **MAE**  | Robuste aux outliers               | Quand outliers dans les erreurs     |
| **R¬≤**   | Proportion de variance expliqu√©e   | Comparaison de mod√®les              |
| **MAPE** | Erreur en pourcentage              | Quand √©chelles variables            |

---

## Phase 6 : D√©ploiement

### Checklist de D√©ploiement

- [ ] **S√©rialiser le mod√®le**

  ```python
  import joblib
  joblib.dump(model, 'model.pkl')
  # ou
  import pickle
  with open('model.pkl', 'wb') as f:
      pickle.dump(model, f)
  ```

- [ ] **Cr√©er une API** (Flask/FastAPI)
- [ ] **Dockeriser l'application**
- [ ] **Tests unitaires**
- [ ] **CI/CD pipeline**
- [ ] **Monitoring des performances**
- [ ] **Logging des pr√©dictions**
- [ ] **Gestion des versions**
- [ ] **Documentation**

---

## Questions Critiques √† se Poser

### Avant de Commencer

1. **Le ML est-il n√©cessaire ?**

   - Peut-on r√©soudre avec des r√®gles simples ?
   - Y a-t-il assez de donn√©es ?
   - Le ROI justifie-t-il l'investissement ?

2. **Les donn√©es sont-elles de qualit√© ?**

   - Repr√©sentatives de la population cible ?
   - R√©centes et √† jour ?
   - Suffisamment volumineuses ?
   - Bien labelis√©es (supervis√©) ?

3. **Le probl√®me est-il bien d√©fini ?**
   - Objectifs clairs et mesurables ?
   - Crit√®res de succ√®s d√©finis ?
   - Contraintes identifi√©es ?

### Pendant le Projet

4. **Le mod√®le apprend-il correctement ?**

   - Overfitting ? (train >> val)
   - Underfitting ? (train et val faibles)
   - Convergence atteinte ?

5. **Les performances sont-elles suffisantes ?**

   - Meilleures que la baseline ?
   - Atteignent les objectifs ?
   - G√©n√©ralisent sur nouvelles donn√©es ?

6. **Le mod√®le est-il interpr√©table ?**
   - Features importantes identifi√©es ?
   - Pr√©dictions expliquables ?
   - Confiance dans les pr√©dictions ?

### Avant D√©ploiement

7. **Le mod√®le est-il robuste ?**

   - Test√© sur cas limites ?
   - G√®re les donn√©es manquantes ?
   - Stable dans le temps ?

8. **Le syst√®me est-il pr√™t ?**
   - Infrastructure scalable ?
   - Monitoring en place ?
   - Plan de maintenance d√©fini ?

---

## Templates de Documentation

### Template de Rapport de Projet

```markdown
# Rapport Projet ML : [Nom du Projet]

## 1. R√©sum√© Ex√©cutif

- Probl√©matique : [...]
- Solution : [...]
- R√©sultats : [...]
- Impact : [...]

## 2. Contexte et Objectifs

### 2.1 Contexte

[Description du contexte m√©tier]

### 2.2 Probl√©matique

[Probl√®me √† r√©soudre]

### 2.3 Objectifs

- Objectif principal : [...]
- Objectifs secondaires : [...]
- Crit√®res de succ√®s : [...]

## 3. Donn√©es

### 3.1 Sources

[Sources de donn√©es utilis√©es]

### 3.2 Description

- Volume : [...]
- P√©riode : [...]
- Features : [...]

### 3.3 Qualit√©

- Valeurs manquantes : [...]
- Outliers : [...]
- Distribution : [...]

## 4. M√©thodologie

### 4.1 Pr√©paration des Donn√©es

[√âtapes de preprocessing]

### 4.2 Feature Engineering

[Features cr√©√©es]

### 4.3 Mod√©lisation

- Mod√®les test√©s : [...]
- Mod√®le s√©lectionn√© : [...]
- Hyperparam√®tres : [...]

## 5. R√©sultats

### 5.1 Performances

- M√©trique principale : [...]
- M√©triques secondaires : [...]
- Comparaison baseline : [...]

### 5.2 Analyse

[Analyse des r√©sultats, features importantes, etc.]

## 6. D√©ploiement

### 6.1 Architecture

[Sch√©ma de d√©ploiement]

### 6.2 Monitoring

[M√©triques suivies]

## 7. Conclusion et Recommandations

### 7.1 Conclusion

[Synth√®se]

### 7.2 Limitations

[Limitations identifi√©es]

### 7.3 Perspectives

[Am√©liorations futures]
```

---

## Checklist Finale

### Avant de Valider le Projet

- [ ] Probl√©matique claire et objectifs d√©finis
- [ ] Donn√©es collect√©es et analys√©es
- [ ] EDA compl√©t√©e
- [ ] Preprocessing et feature engineering document√©s
- [ ] Plusieurs mod√®les test√©s
- [ ] Baseline d√©pass√©e
- [ ] Hyperparam√®tres optimis√©s
- [ ] Cross-validation effectu√©e
- [ ] √âvaluation sur test set
- [ ] Analyse des erreurs
- [ ] Features importantes identifi√©es
- [ ] Mod√®le s√©rialis√©
- [ ] Documentation compl√®te
- [ ] Code versionn√© (git)
- [ ] Tests unitaires
- [ ] Rapport de projet r√©dig√©

---

**üéØ Avec ce guide, vous avez toutes les cl√©s pour mener √† bien un projet ML de A √† Z !**

---

**Navigation :**

- [‚û°Ô∏è Guide de D√©cision ML](00_Guide_Decision_ML.md)
- [‚û°Ô∏è Workflows ML](00_Workflows_ML.md)
- [üè† Retour au Sommaire](README_ML.md)
