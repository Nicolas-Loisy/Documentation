# Guide Complet : DÃ©marrer un Projet Machine Learning

## ğŸ“‹ Table des MatiÃ¨res
1. [Checklist ComplÃ¨te d'un Projet ML](#checklist-complÃ¨te-dun-projet-ml)
2. [Phase 1 : ComprÃ©hension du ProblÃ¨me](#phase-1--comprÃ©hension-du-problÃ¨me)
3. [Phase 2 : Collecte et Exploration des DonnÃ©es](#phase-2--collecte-et-exploration-des-donnÃ©es)
4. [Phase 3 : PrÃ©paration des DonnÃ©es](#phase-3--prÃ©paration-des-donnÃ©es)
5. [Phase 4 : ModÃ©lisation](#phase-4--modÃ©lisation)
6. [Phase 5 : Ã‰valuation](#phase-5--Ã©valuation)
7. [Phase 6 : DÃ©ploiement](#phase-6--dÃ©ploiement)
8. [Questions Critiques Ã  se Poser](#questions-critiques-Ã -se-poser)
9. [Templates de Documentation](#templates-de-documentation)

---

## Checklist ComplÃ¨te d'un Projet ML

### âœ… Phase 1 : ComprÃ©hension du ProblÃ¨me
- [ ] DÃ©finir la problÃ©matique mÃ©tier clairement
- [ ] Identifier les objectifs mesurables
- [ ] DÃ©terminer le type de problÃ¨me ML
- [ ] Ã‰valuer la faisabilitÃ© du projet
- [ ] DÃ©finir les critÃ¨res de succÃ¨s
- [ ] Identifier les contraintes (temps, budget, ressources)
- [ ] Comprendre l'impact business

### âœ… Phase 2 : Collecte et Exploration des DonnÃ©es
- [ ] Identifier les sources de donnÃ©es disponibles
- [ ] Collecter les donnÃ©es nÃ©cessaires
- [ ] VÃ©rifier la qualitÃ© des donnÃ©es
- [ ] Analyser les statistiques descriptives
- [ ] Visualiser les distributions
- [ ] Identifier les valeurs manquantes
- [ ] DÃ©tecter les outliers
- [ ] Analyser les corrÃ©lations entre variables

### âœ… Phase 3 : PrÃ©paration des DonnÃ©es
- [ ] Traiter les valeurs manquantes
- [ ] GÃ©rer les outliers
- [ ] Encoder les variables catÃ©gorielles
- [ ] Normaliser/standardiser les variables numÃ©riques
- [ ] CrÃ©er de nouvelles features (feature engineering)
- [ ] SÃ©lectionner les features pertinentes
- [ ] Diviser les donnÃ©es (train/validation/test)
- [ ] GÃ©rer le dÃ©sÃ©quilibre des classes (si nÃ©cessaire)

### âœ… Phase 4 : ModÃ©lisation
- [ ] Choisir les modÃ¨les candidats
- [ ] DÃ©finir la baseline
- [ ] EntraÃ®ner les modÃ¨les
- [ ] Optimiser les hyperparamÃ¨tres
- [ ] Valider avec cross-validation
- [ ] Comparer les performances
- [ ] SÃ©lectionner le meilleur modÃ¨le
- [ ] Analyser les erreurs

### âœ… Phase 5 : Ã‰valuation
- [ ] Ã‰valuer sur le test set
- [ ] Calculer les mÃ©triques appropriÃ©es
- [ ] Analyser la matrice de confusion (classification)
- [ ] VÃ©rifier l'overfitting/underfitting
- [ ] Tester sur cas limites
- [ ] InterprÃ©ter les prÃ©dictions
- [ ] Documenter les rÃ©sultats

### âœ… Phase 6 : DÃ©ploiement
- [ ] PrÃ©parer le modÃ¨le pour production
- [ ] CrÃ©er une API ou interface
- [ ] Mettre en place le monitoring
- [ ] Tester en environnement rÃ©el
- [ ] Former les utilisateurs
- [ ] Planifier la maintenance
- [ ] PrÃ©voir le retraining

---

## Phase 1 : ComprÃ©hension du ProblÃ¨me

### Questions Essentielles

#### 1. Quelle est la problÃ©matique mÃ©tier ?

**Template de problÃ©matique :**
```
Contexte : [DÃ©crire la situation actuelle]
ProblÃ¨me : [Quel problÃ¨me cherche-t-on Ã  rÃ©soudre ?]
Impact : [Quelles sont les consÃ©quences du problÃ¨me ?]
Solution envisagÃ©e : [Comment le ML peut-il aider ?]
```

**Exemple :**
```
Contexte : Une banque reÃ§oit des milliers de demandes de crÃ©dit par jour
ProblÃ¨me : Le processus d'Ã©valuation manuel est lent et coÃ»teux
Impact : Perte de clients, coÃ»ts opÃ©rationnels Ã©levÃ©s
Solution envisagÃ©e : SystÃ¨me automatisÃ© de prÃ©diction de dÃ©faut de paiement
```

#### 2. Quel est le type de problÃ¨me ML ?

| Type | Description | Exemples |
|------|-------------|----------|
| **Classification binaire** | 2 classes | Spam/Non-spam, Fraude/LÃ©gitime |
| **Classification multi-classe** | >2 classes | Reconnaissance de chiffres, CatÃ©gorisation de produits |
| **RÃ©gression** | PrÃ©diction valeur continue | Prix immobilier, TempÃ©rature |
| **Clustering** | Groupement sans labels | Segmentation client |
| **DÃ©tection d'anomalies** | Identifier les outliers | Fraude, DÃ©fauts industriels |
| **SÃ©ries temporelles** | PrÃ©diction temporelle | PrÃ©vision des ventes, Prix boursiers |
| **NLP** | Traitement du langage | Analyse de sentiment, Traduction |
| **Vision** | Traitement d'images | DÃ©tection d'objets, Classification d'images |

#### 3. Quels sont les objectifs mesurables ?

**Template d'objectifs :**
```
Objectif principal : [MÃ©trique cible]
  - Actuel : [Valeur baseline]
  - Cible : [Valeur Ã  atteindre]
  - DÃ©lai : [Quand ?]

Objectifs secondaires :
  - [Autre mÃ©trique 1]
  - [Autre mÃ©trique 2]
```

**Exemple :**
```
Objectif principal : RÃ©duire le taux de dÃ©faut de paiement
  - Actuel : 15% des crÃ©dits accordÃ©s
  - Cible : <8% des crÃ©dits accordÃ©s
  - DÃ©lai : 6 mois

Objectifs secondaires :
  - RÃ©duire le temps de traitement de 5 jours Ã  1 heure
  - Maintenir un taux d'approbation >70%
```

#### 4. Quelles sont les contraintes ?

**Contraintes Ã  identifier :**

| Type | Questions |
|------|-----------|
| **Temps** | Quelle est la deadline ? Temps d'infÃ©rence acceptable ? |
| **Budget** | Ressources de calcul disponibles ? Budget cloud ? |
| **DonnÃ©es** | QuantitÃ© de donnÃ©es disponibles ? QualitÃ© ? Labels ? |
| **InterprÃ©tabilitÃ©** | Le modÃ¨le doit-il Ãªtre explicable ? (mÃ©dical, finance) |
| **PrÃ©cision** | Quelle prÃ©cision minimale ? Quel type d'erreur est acceptable ? |
| **DÃ©ploiement** | Edge device ? Cloud ? On-premise ? |
| **LÃ©gal** | RGPD ? Autres rÃ©glementations ? |

#### 5. DÃ©finir les critÃ¨res de succÃ¨s

**CritÃ¨res techniques :**
- MÃ©triques de performance (accuracy, F1, RMSE, etc.)
- Temps d'infÃ©rence
- Taille du modÃ¨le
- Robustesse

**CritÃ¨res business :**
- ROI attendu
- RÃ©duction des coÃ»ts
- AmÃ©lioration de l'expÃ©rience utilisateur
- Gain de productivitÃ©

---

## Phase 2 : Collecte et Exploration des DonnÃ©es

### Questions sur les DonnÃ©es

#### 1. Quelles donnÃ©es sont disponibles ?

**Checklist des donnÃ©es :**
```python
# Template d'inventaire des donnÃ©es
donnees_disponibles = {
    'source_1': {
        'type': 'Base de donnÃ©es SQL',
        'volume': '1M lignes',
        'periode': '2020-2024',
        'format': 'StructurÃ©',
        'qualite': 'Bonne',
        'acces': 'API',
        'cout': 'Gratuit'
    },
    'source_2': {
        'type': 'Fichiers CSV',
        'volume': '500K lignes',
        'periode': '2022-2024',
        'format': 'Semi-structurÃ©',
        'qualite': 'Moyenne (valeurs manquantes)',
        'acces': 'FTP',
        'cout': 'Gratuit'
    }
}
```

#### 2. Quel est le type de donnÃ©es ?

| Type | Exemples | PrÃ©paration |
|------|----------|-------------|
| **NumÃ©riques continues** | Prix, tempÃ©rature, Ã¢ge | Normalisation, standardisation |
| **NumÃ©riques discrÃ¨tes** | Nombre de produits, compteurs | Binning possible |
| **CatÃ©gorielles ordinales** | Niveau d'Ã©ducation, taille (S/M/L) | Ordinal encoding |
| **CatÃ©gorielles nominales** | Couleur, ville, catÃ©gorie | One-hot encoding, target encoding |
| **Temporelles** | Date, heure, timestamp | Feature engineering (jour, mois, etc.) |
| **Texte** | Avis, descriptions | TF-IDF, embeddings |
| **Images** | Photos, scans | Normalisation, augmentation |
| **Audio** | Voix, sons | Spectrogrammes, MFCC |

#### 3. Analyse Exploratoire des DonnÃ©es (EDA)

**Script EDA Standard :**

```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

def analyse_exploratoire(df):
    """
    Analyse exploratoire complÃ¨te d'un DataFrame
    """
    print("="*80)
    print("1. INFORMATIONS GÃ‰NÃ‰RALES")
    print("="*80)
    print(f"Dimensions : {df.shape[0]} lignes Ã— {df.shape[1]} colonnes")
    print(f"\nMÃ©moire utilisÃ©e : {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB")

    print("\n" + "="*80)
    print("2. TYPES DE DONNÃ‰ES")
    print("="*80)
    print(df.dtypes.value_counts())

    print("\n" + "="*80)
    print("3. VALEURS MANQUANTES")
    print("="*80)
    missing = df.isnull().sum()
    missing_pct = 100 * missing / len(df)
    missing_table = pd.DataFrame({
        'Manquantes': missing,
        'Pourcentage': missing_pct
    })
    print(missing_table[missing_table['Manquantes'] > 0].sort_values('Pourcentage', ascending=False))

    print("\n" + "="*80)
    print("4. STATISTIQUES DESCRIPTIVES")
    print("="*80)
    print(df.describe())

    print("\n" + "="*80)
    print("5. DOUBLONS")
    print("="*80)
    duplicates = df.duplicated().sum()
    print(f"Nombre de doublons : {duplicates} ({100*duplicates/len(df):.2f}%)")

    print("\n" + "="*80)
    print("6. CARDINALITÃ‰ DES VARIABLES CATÃ‰GORIELLES")
    print("="*80)
    cat_cols = df.select_dtypes(include=['object', 'category']).columns
    for col in cat_cols:
        print(f"{col}: {df[col].nunique()} valeurs uniques")
        if df[col].nunique() <= 10:
            print(df[col].value_counts())
        print()

    # Visualisations
    print("\n" + "="*80)
    print("7. VISUALISATIONS")
    print("="*80)

    # Distribution des variables numÃ©riques
    num_cols = df.select_dtypes(include=[np.number]).columns
    if len(num_cols) > 0:
        fig, axes = plt.subplots(len(num_cols), 2, figsize=(15, 5*len(num_cols)))
        if len(num_cols) == 1:
            axes = axes.reshape(1, -1)

        for idx, col in enumerate(num_cols):
            # Histogramme
            axes[idx, 0].hist(df[col].dropna(), bins=30, edgecolor='black')
            axes[idx, 0].set_title(f'Distribution de {col}')
            axes[idx, 0].set_xlabel(col)
            axes[idx, 0].set_ylabel('FrÃ©quence')

            # Boxplot
            axes[idx, 1].boxplot(df[col].dropna())
            axes[idx, 1].set_title(f'Boxplot de {col}')
            axes[idx, 1].set_ylabel(col)

        plt.tight_layout()
        plt.show()

    # Matrice de corrÃ©lation
    if len(num_cols) > 1:
        plt.figure(figsize=(12, 10))
        correlation = df[num_cols].corr()
        sns.heatmap(correlation, annot=True, fmt='.2f', cmap='coolwarm',
                    square=True, linewidths=0.5)
        plt.title('Matrice de CorrÃ©lation')
        plt.tight_layout()
        plt.show()

    return {
        'shape': df.shape,
        'missing': missing_table[missing_table['Manquantes'] > 0],
        'duplicates': duplicates,
        'dtypes': df.dtypes
    }

# Utilisation
# resultats = analyse_exploratoire(df)
```

#### 4. Questions sur la QualitÃ© des DonnÃ©es

**Checklist qualitÃ© :**

- [ ] **ComplÃ©tude** : Taux de valeurs manquantes acceptable ?
- [ ] **CohÃ©rence** : Les valeurs sont-elles cohÃ©rentes ? (ex: Ã¢ge nÃ©gatif)
- [ ] **PrÃ©cision** : Les donnÃ©es sont-elles exactes ?
- [ ] **ActualitÃ©** : Les donnÃ©es sont-elles Ã  jour ?
- [ ] **UnicitÃ©** : Y a-t-il des doublons ?
- [ ] **ReprÃ©sentativitÃ©** : Les donnÃ©es reflÃ¨tent-elles la population cible ?
- [ ] **Ã‰quilibre** : Les classes sont-elles Ã©quilibrÃ©es (classification) ?

---

## Phase 3 : PrÃ©paration des DonnÃ©es

### 1. Traitement des Valeurs Manquantes

#### StratÃ©gies selon le contexte

```python
# DÃ©cision : Comment traiter les valeurs manquantes ?

def strategie_valeurs_manquantes(df, col):
    """
    Guide de dÃ©cision pour valeurs manquantes
    """
    missing_pct = df[col].isnull().sum() / len(df) * 100

    print(f"Colonne : {col}")
    print(f"Valeurs manquantes : {missing_pct:.2f}%")

    if missing_pct > 50:
        print("â†’ RECOMMANDATION : Supprimer la colonne (trop de valeurs manquantes)")
    elif missing_pct > 20:
        print("â†’ RECOMMANDATION : Imputation avancÃ©e ou crÃ©er feature 'is_missing'")
    else:
        if df[col].dtype in ['int64', 'float64']:
            print("â†’ OPTIONS :")
            print("  - Imputation par la moyenne (si distribution normale)")
            print("  - Imputation par la mÃ©diane (si outliers)")
            print("  - Imputation par rÃ©gression/KNN (si corrÃ©lÃ© Ã  autres features)")
        else:
            print("â†’ OPTIONS :")
            print("  - Imputation par le mode")
            print("  - Imputation par 'Unknown' / 'Missing'")
            print("  - Imputation par modÃ¨le (classification)")
    print()

# MÃ©thodes d'imputation
from sklearn.impute import SimpleImputer, KNNImputer

# 1. Imputation simple
imputer_mean = SimpleImputer(strategy='mean')  # moyenne
imputer_median = SimpleImputer(strategy='median')  # mÃ©diane
imputer_mode = SimpleImputer(strategy='most_frequent')  # mode

# 2. Imputation KNN
imputer_knn = KNNImputer(n_neighbors=5)

# 3. Imputation par rÃ©gression
from sklearn.experimental import enable_iterative_imputer
from sklearn.impute import IterativeImputer
imputer_iter = IterativeImputer(max_iter=10, random_state=42)
```

### 2. Gestion des Outliers

#### DÃ©tection

```python
def detecter_outliers(df, col):
    """
    DÃ©tecte les outliers par plusieurs mÃ©thodes
    """
    print(f"Analyse des outliers pour : {col}")
    print("="*60)

    # MÃ©thode 1 : IQR
    Q1 = df[col].quantile(0.25)
    Q3 = df[col].quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR

    outliers_iqr = df[(df[col] < lower_bound) | (df[col] > upper_bound)]
    print(f"MÃ©thode IQR : {len(outliers_iqr)} outliers ({len(outliers_iqr)/len(df)*100:.2f}%)")
    print(f"  Bornes : [{lower_bound:.2f}, {upper_bound:.2f}]")

    # MÃ©thode 2 : Z-score
    from scipy import stats
    z_scores = np.abs(stats.zscore(df[col].dropna()))
    outliers_z = df[np.abs(z_scores) > 3]
    print(f"MÃ©thode Z-score (>3) : {len(outliers_z)} outliers ({len(outliers_z)/len(df)*100:.2f}%)")

    # MÃ©thode 3 : Isolation Forest
    from sklearn.ensemble import IsolationForest
    iso = IsolationForest(contamination=0.1, random_state=42)
    outliers_iso = iso.fit_predict(df[[col]])
    n_outliers_iso = (outliers_iso == -1).sum()
    print(f"MÃ©thode Isolation Forest : {n_outliers_iso} outliers ({n_outliers_iso/len(df)*100:.2f}%)")

    # Visualisation
    fig, axes = plt.subplots(1, 2, figsize=(14, 5))

    # Boxplot
    axes[0].boxplot(df[col].dropna())
    axes[0].set_title(f'Boxplot - {col}')
    axes[0].axhline(lower_bound, color='r', linestyle='--', label='Borne IQR inf')
    axes[0].axhline(upper_bound, color='r', linestyle='--', label='Borne IQR sup')
    axes[0].legend()

    # Distribution
    axes[1].hist(df[col].dropna(), bins=50, edgecolor='black')
    axes[1].axvline(lower_bound, color='r', linestyle='--')
    axes[1].axvline(upper_bound, color='r', linestyle='--')
    axes[1].set_title(f'Distribution - {col}')
    axes[1].set_xlabel(col)

    plt.tight_layout()
    plt.show()

    return {
        'iqr': outliers_iqr.index,
        'z_score': outliers_z.index,
        'isolation_forest': df.index[outliers_iso == -1]
    }

# StratÃ©gies de traitement
def traiter_outliers(df, col, method='cap'):
    """
    Traite les outliers selon la mÃ©thode choisie

    Methods:
    - 'remove': Supprimer les outliers
    - 'cap': Capping (remplacer par les bornes)
    - 'log': Transformation logarithmique
    - 'winsorize': Winsorisation
    """
    if method == 'remove':
        # IQR
        Q1 = df[col].quantile(0.25)
        Q3 = df[col].quantile(0.75)
        IQR = Q3 - Q1
        lower = Q1 - 1.5 * IQR
        upper = Q3 + 1.5 * IQR
        df = df[(df[col] >= lower) & (df[col] <= upper)]

    elif method == 'cap':
        # Capping
        Q1 = df[col].quantile(0.25)
        Q3 = df[col].quantile(0.75)
        IQR = Q3 - Q1
        lower = Q1 - 1.5 * IQR
        upper = Q3 + 1.5 * IQR
        df[col] = df[col].clip(lower, upper)

    elif method == 'log':
        # Log transformation
        df[col] = np.log1p(df[col])

    elif method == 'winsorize':
        # Winsorisation
        from scipy.stats.mstats import winsorize
        df[col] = winsorize(df[col], limits=[0.05, 0.05])

    return df
```

### 3. Feature Engineering

#### Questions sur les Features

```python
# Guide de Feature Engineering

"""
QUESTIONS Ã€ SE POSER :

1. Combinaisons de features
   - Peut-on crÃ©er des ratios ? (ex: prix/mÂ²)
   - Peut-on crÃ©er des diffÃ©rences ? (ex: Ã¢ge_max - Ã¢ge_min)
   - Peut-on crÃ©er des produits ? (ex: longueur Ã— largeur)

2. Extraction d'information
   - Dates : jour, mois, annÃ©e, jour de semaine, trimestre, est_weekend
   - Texte : longueur, nombre de mots, sentiment, entitÃ©s
   - CatÃ©gories : frÃ©quence, regroupement

3. Transformations
   - Log, sqrt, carrÃ© (pour normaliser distributions)
   - Binning (discrÃ©tisation)
   - Polynomiales (pour capturer non-linÃ©aritÃ©)

4. AgrÃ©gations
   - Groupby + statistiques (mean, sum, count, etc.)
   - Rolling windows (sÃ©ries temporelles)

5. Encoding
   - One-hot encoding (peu de catÃ©gories)
   - Target encoding (beaucoup de catÃ©gories)
   - Frequency encoding
   - Embedding (Deep Learning)
"""

# Exemples de Feature Engineering

def feature_engineering_dates(df, date_col):
    """
    Extrait des features d'une colonne date
    """
    df[date_col] = pd.to_datetime(df[date_col])

    df[f'{date_col}_year'] = df[date_col].dt.year
    df[f'{date_col}_month'] = df[date_col].dt.month
    df[f'{date_col}_day'] = df[date_col].dt.day
    df[f'{date_col}_dayofweek'] = df[date_col].dt.dayofweek
    df[f'{date_col}_quarter'] = df[date_col].dt.quarter
    df[f'{date_col}_is_weekend'] = df[date_col].dt.dayofweek.isin([5, 6]).astype(int)
    df[f'{date_col}_is_month_start'] = df[date_col].dt.is_month_start.astype(int)
    df[f'{date_col}_is_month_end'] = df[date_col].dt.is_month_end.astype(int)

    return df

def feature_engineering_agregations(df, group_col, agg_col):
    """
    CrÃ©e des features d'agrÃ©gation
    """
    agg_features = df.groupby(group_col)[agg_col].agg([
        'mean', 'median', 'std', 'min', 'max', 'sum', 'count'
    ]).reset_index()

    agg_features.columns = [group_col] + [f'{agg_col}_{stat}_by_{group_col}'
                                          for stat in ['mean', 'median', 'std', 'min', 'max', 'sum', 'count']]

    df = df.merge(agg_features, on=group_col, how='left')
    return df

def feature_engineering_interactions(df, cols):
    """
    CrÃ©e des interactions entre features
    """
    for i, col1 in enumerate(cols):
        for col2 in cols[i+1:]:
            # Produit
            df[f'{col1}_x_{col2}'] = df[col1] * df[col2]
            # Ratio
            df[f'{col1}_div_{col2}'] = df[col1] / (df[col2] + 1e-5)
            # DiffÃ©rence
            df[f'{col1}_minus_{col2}'] = df[col1] - df[col2]

    return df
```

### 4. Encodage des Variables CatÃ©gorielles

```python
from sklearn.preprocessing import LabelEncoder, OneHotEncoder
from category_encoders import TargetEncoder

def guide_encodage(df, col, target=None):
    """
    Guide pour choisir la mÃ©thode d'encodage
    """
    n_unique = df[col].nunique()

    print(f"Colonne : {col}")
    print(f"Nombre de catÃ©gories uniques : {n_unique}")

    if n_unique == 2:
        print("â†’ RECOMMANDATION : Label Encoding (2 catÃ©gories)")
        print("  from sklearn.preprocessing import LabelEncoder")
    elif n_unique <= 10:
        print("â†’ RECOMMANDATION : One-Hot Encoding")
        print("  pd.get_dummies() ou OneHotEncoder")
    elif n_unique <= 50:
        print("â†’ RECOMMANDATION : Target Encoding ou Frequency Encoding")
        print("  from category_encoders import TargetEncoder")
    else:
        print("â†’ RECOMMANDATION : Target Encoding, Hashing ou Embedding")
        print("  Attention au overfitting avec Target Encoding")
    print()

# 1. Label Encoding (ordinale ou binaire)
le = LabelEncoder()
df['col_encoded'] = le.fit_transform(df['col'])

# 2. One-Hot Encoding
df_encoded = pd.get_dummies(df, columns=['col'], drop_first=True)

# 3. Target Encoding
te = TargetEncoder()
df['col_encoded'] = te.fit_transform(df['col'], df['target'])

# 4. Frequency Encoding
freq = df['col'].value_counts(normalize=True)
df['col_encoded'] = df['col'].map(freq)
```

### 5. Normalisation et Standardisation

```python
from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler

def guide_normalisation(df, col):
    """
    Guide pour choisir la mÃ©thode de normalisation
    """
    print(f"Analyse de {col}")
    print("="*60)

    # Statistiques
    mean = df[col].mean()
    median = df[col].median()
    std = df[col].std()
    skew = df[col].skew()

    print(f"Moyenne : {mean:.2f}")
    print(f"MÃ©diane : {median:.2f}")
    print(f"Ã‰cart-type : {std:.2f}")
    print(f"Skewness : {skew:.2f}")

    # Recommandation
    if abs(skew) < 0.5:
        print("\nâ†’ Distribution proche de la normale")
        print("  RECOMMANDATION : StandardScaler (Z-score)")
    elif abs(skew) >= 0.5:
        print("\nâ†’ Distribution asymÃ©trique")
        print("  RECOMMANDATION : RobustScaler (rÃ©sistant aux outliers)")

    print("\nâ†’ Pour borner les valeurs dans [0,1] : MinMaxScaler")
    print("â†’ Pour rÃ©seaux de neurones : Normalisation [0,1] ou [-1,1] recommandÃ©e")
    print()

# MÃ©thodes de normalisation

# 1. Standardisation (Z-score) : moyenne=0, Ã©cart-type=1
scaler = StandardScaler()
df_scaled = scaler.fit_transform(df[num_cols])

# 2. Min-Max : valeurs dans [0, 1]
scaler = MinMaxScaler()
df_scaled = scaler.fit_transform(df[num_cols])

# 3. Robust : rÃ©sistant aux outliers
scaler = RobustScaler()
df_scaled = scaler.fit_transform(df[num_cols])
```

---

## Phase 4 : ModÃ©lisation

### Questions pour Choisir un ModÃ¨le

#### Arbre de DÃ©cision

```
1. Quel est le type de problÃ¨me ?
   â”œâ”€ Classification
   â”‚  â”œâ”€ LinÃ©airement sÃ©parable ? â†’ Logistic Regression, SVM linÃ©aire
   â”‚  â”œâ”€ Non-linÃ©aire ?
   â”‚  â”‚  â”œâ”€ Petites donnÃ©es (<10k) â†’ SVM (kernel RBF), Decision Tree
   â”‚  â”‚  â”œâ”€ Moyennes donnÃ©es (10k-100k) â†’ Random Forest, XGBoost
   â”‚  â”‚  â””â”€ Grandes donnÃ©es (>100k) â†’ XGBoost, LightGBM, Deep Learning
   â”‚  â””â”€ InterprÃ©tabilitÃ© requise ? â†’ Logistic Regression, Decision Tree
   â”‚
   â”œâ”€ RÃ©gression
   â”‚  â”œâ”€ Relation linÃ©aire ? â†’ Linear Regression, Ridge, Lasso
   â”‚  â”œâ”€ Non-linÃ©aire ?
   â”‚  â”‚  â”œâ”€ Petites donnÃ©es â†’ SVR, Decision Tree
   â”‚  â”‚  â”œâ”€ Moyennes donnÃ©es â†’ Random Forest, XGBoost
   â”‚  â”‚  â””â”€ Grandes donnÃ©es â†’ XGBoost, LightGBM, Deep Learning
   â”‚  â””â”€ InterprÃ©tabilitÃ© ? â†’ Linear Regression, Decision Tree
   â”‚
   â”œâ”€ Clustering
   â”‚  â”œâ”€ Nombre de clusters connu ? â†’ K-Means
   â”‚  â”œâ”€ Clusters de formes arbitraires ? â†’ DBSCAN, HDBSCAN
   â”‚  â””â”€ HiÃ©rarchie importante ? â†’ Hierarchical Clustering
   â”‚
   â”œâ”€ RÃ©duction de dimensionnalitÃ©
   â”‚  â”œâ”€ LinÃ©aire + compression â†’ PCA
   â”‚  â”œâ”€ Visualisation â†’ t-SNE, UMAP
   â”‚  â””â”€ Non-linÃ©aire + gÃ©nÃ©ration â†’ Autoencoder
   â”‚
   â””â”€ DÃ©tection d'anomalies
      â”œâ”€ Isolation â†’ Isolation Forest
      â”œâ”€ FrontiÃ¨re distribution â†’ One-Class SVM
      â””â”€ Reconstruction â†’ Autoencoder

2. Quelle est la taille des donnÃ©es ?
   - <1k : Simple models (Decision Tree, Logistic Regression)
   - 1k-100k : Ensemble methods (Random Forest, XGBoost)
   - >100k : Gradient Boosting, Deep Learning

3. Quel est le type de donnÃ©es ?
   - Tabulaires : XGBoost, Random Forest
   - Images : CNN (ResNet, EfficientNet)
   - Texte : Transformers (BERT), RNN
   - SÃ©ries temporelles : LSTM, GRU, Prophet

4. Contraintes de temps ?
   - EntraÃ®nement rapide : Logistic Regression, Decision Tree
   - InfÃ©rence rapide : Linear models, petits trees
   - Temps non contraint : Deep Learning, XGBoost avec tuning
```

### Workflow de ModÃ©lisation

```python
from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV
from sklearn.metrics import accuracy_score, f1_score, mean_squared_error

# 1. Diviser les donnÃ©es
X_train, X_temp, y_train, y_temp = train_test_split(
    X, y, test_size=0.3, random_state=42, stratify=y  # stratify pour classification
)
X_val, X_test, y_val, y_test = train_test_split(
    X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp
)

print(f"Train: {len(X_train)} | Validation: {len(X_val)} | Test: {len(X_test)}")

# 2. DÃ©finir la baseline
from sklearn.dummy import DummyClassifier

baseline = DummyClassifier(strategy='most_frequent')
baseline.fit(X_train, y_train)
baseline_score = baseline.score(X_val, y_val)
print(f"Baseline Accuracy: {baseline_score:.4f}")

# 3. Tester plusieurs modÃ¨les
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier

models = {
    'Logistic Regression': LogisticRegression(max_iter=1000),
    'Decision Tree': DecisionTreeClassifier(random_state=42),
    'Random Forest': RandomForestClassifier(random_state=42, n_estimators=100),
    'XGBoost': XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss')
}

results = {}

for name, model in models.items():
    # EntraÃ®ner
    model.fit(X_train, y_train)

    # Ã‰valuer
    train_score = model.score(X_train, y_train)
    val_score = model.score(X_val, y_val)

    # Cross-validation
    cv_scores = cross_val_score(model, X_train, y_train, cv=5)

    results[name] = {
        'train_score': train_score,
        'val_score': val_score,
        'cv_mean': cv_scores.mean(),
        'cv_std': cv_scores.std()
    }

    print(f"\n{name}")
    print(f"  Train: {train_score:.4f}")
    print(f"  Val: {val_score:.4f}")
    print(f"  CV: {cv_scores.mean():.4f} (+/- {cv_scores.std():.4f})")
    print(f"  Overfitting: {train_score - val_score:.4f}")

# 4. SÃ©lectionner le meilleur modÃ¨le
best_model_name = max(results, key=lambda k: results[k]['val_score'])
print(f"\nğŸ† Meilleur modÃ¨le : {best_model_name}")

# 5. Optimiser les hyperparamÃ¨tres
if best_model_name == 'XGBoost':
    param_grid = {
        'n_estimators': [100, 200, 300],
        'max_depth': [3, 5, 7],
        'learning_rate': [0.01, 0.1, 0.3],
        'subsample': [0.8, 1.0]
    }

    grid_search = GridSearchCV(
        XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss'),
        param_grid,
        cv=5,
        scoring='accuracy',
        n_jobs=-1,
        verbose=1
    )

    grid_search.fit(X_train, y_train)

    print(f"\nMeilleurs paramÃ¨tres : {grid_search.best_params_}")
    print(f"Meilleur score CV : {grid_search.best_score_:.4f}")

    best_model = grid_search.best_estimator_

# 6. Ã‰valuation finale sur test set
y_pred_test = best_model.predict(X_test)
test_score = accuracy_score(y_test, y_pred_test)
print(f"\nğŸ“Š Score final sur test set : {test_score:.4f}")
```

---

## Phase 5 : Ã‰valuation

### MÃ©triques selon le Type de ProblÃ¨me

#### Classification

```python
from sklearn.metrics import (
    accuracy_score, precision_score, recall_score, f1_score,
    confusion_matrix, classification_report, roc_auc_score, roc_curve
)

def evaluation_classification(y_true, y_pred, y_proba=None):
    """
    Ã‰valuation complÃ¨te pour classification
    """
    print("="*80)
    print("Ã‰VALUATION - CLASSIFICATION")
    print("="*80)

    # MÃ©triques de base
    acc = accuracy_score(y_true, y_pred)
    prec = precision_score(y_true, y_pred, average='weighted')
    rec = recall_score(y_true, y_pred, average='weighted')
    f1 = f1_score(y_true, y_pred, average='weighted')

    print(f"\nAccuracy  : {acc:.4f}")
    print(f"Precision : {prec:.4f}")
    print(f"Recall    : {rec:.4f}")
    print(f"F1-Score  : {f1:.4f}")

    # Matrice de confusion
    print("\nMatrice de Confusion :")
    cm = confusion_matrix(y_true, y_pred)
    print(cm)

    # Classification report
    print("\nClassification Report :")
    print(classification_report(y_true, y_pred))

    # ROC-AUC (si probabilitÃ©s disponibles)
    if y_proba is not None:
        if len(np.unique(y_true)) == 2:  # Binaire
            auc = roc_auc_score(y_true, y_proba[:, 1])
            print(f"\nROC-AUC : {auc:.4f}")

            # Courbe ROC
            fpr, tpr, _ = roc_curve(y_true, y_proba[:, 1])
            plt.figure(figsize=(8, 6))
            plt.plot(fpr, tpr, label=f'ROC (AUC = {auc:.4f})')
            plt.plot([0, 1], [0, 1], 'k--', label='Random')
            plt.xlabel('False Positive Rate')
            plt.ylabel('True Positive Rate')
            plt.title('Courbe ROC')
            plt.legend()
            plt.grid(True, alpha=0.3)
            plt.show()

    # Visualisation matrice de confusion
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)
    plt.xlabel('PrÃ©diction')
    plt.ylabel('RÃ©alitÃ©')
    plt.title('Matrice de Confusion')
    plt.show()

# Utilisation
# evaluation_classification(y_test, y_pred, model.predict_proba(X_test))
```

**Guide de choix de mÃ©triques :**

| Contexte | MÃ©trique Principale | Raison |
|----------|---------------------|--------|
| **Classes Ã©quilibrÃ©es** | Accuracy | Simple et suffisant |
| **Classes dÃ©sÃ©quilibrÃ©es** | F1-Score, ROC-AUC | Prend en compte le dÃ©sÃ©quilibre |
| **CoÃ»t des faux nÃ©gatifs Ã©levÃ©** (ex: cancer) | Recall | Minimiser les cas manquÃ©s |
| **CoÃ»t des faux positifs Ã©levÃ©** (ex: spam) | Precision | Minimiser les fausses alarmes |
| **Trade-off** | F1-Score | Ã‰quilibre precision/recall |
| **Ranking/probabilitÃ©s** | ROC-AUC | Ã‰value qualitÃ© des scores |

#### RÃ©gression

```python
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

def evaluation_regression(y_true, y_pred):
    """
    Ã‰valuation complÃ¨te pour rÃ©gression
    """
    print("="*80)
    print("Ã‰VALUATION - RÃ‰GRESSION")
    print("="*80)

    # MÃ©triques
    mse = mean_squared_error(y_true, y_pred)
    rmse = np.sqrt(mse)
    mae = mean_absolute_error(y_true, y_pred)
    r2 = r2_score(y_true, y_pred)

    # MAPE (Mean Absolute Percentage Error)
    mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100

    print(f"\nMSE  : {mse:.4f}")
    print(f"RMSE : {rmse:.4f}")
    print(f"MAE  : {mae:.4f}")
    print(f"RÂ²   : {r2:.4f}")
    print(f"MAPE : {mape:.2f}%")

    # InterprÃ©tation RÂ²
    if r2 > 0.9:
        print("  â†’ Excellent modÃ¨le")
    elif r2 > 0.7:
        print("  â†’ Bon modÃ¨le")
    elif r2 > 0.5:
        print("  â†’ ModÃ¨le acceptable")
    else:
        print("  â†’ ModÃ¨le faible")

    # Visualisations
    fig, axes = plt.subplots(1, 2, figsize=(14, 5))

    # Scatter plot : prÃ©dictions vs rÃ©alitÃ©
    axes[0].scatter(y_true, y_pred, alpha=0.5, edgecolors='k')
    axes[0].plot([y_true.min(), y_true.max()],
                 [y_true.min(), y_true.max()],
                 'r--', lw=2, label='PrÃ©diction parfaite')
    axes[0].set_xlabel('Valeur RÃ©elle')
    axes[0].set_ylabel('PrÃ©diction')
    axes[0].set_title(f'PrÃ©dictions vs RÃ©alitÃ© (RÂ² = {r2:.4f})')
    axes[0].legend()
    axes[0].grid(True, alpha=0.3)

    # Distribution des rÃ©sidus
    residuals = y_true - y_pred
    axes[1].hist(residuals, bins=30, edgecolor='black')
    axes[1].axvline(0, color='r', linestyle='--', linewidth=2)
    axes[1].set_xlabel('RÃ©sidus')
    axes[1].set_ylabel('FrÃ©quence')
    axes[1].set_title(f'Distribution des RÃ©sidus (MAE = {mae:.4f})')
    axes[1].grid(True, alpha=0.3)

    plt.tight_layout()
    plt.show()

# Utilisation
# evaluation_regression(y_test, y_pred)
```

**Guide de choix de mÃ©triques :**

| MÃ©trique | CaractÃ©ristiques | Usage |
|----------|------------------|-------|
| **MSE** | PÃ©nalise fortement grandes erreurs | Quand grandes erreurs inacceptables |
| **RMSE** | MÃªme unitÃ© que la cible | InterprÃ©tation facile |
| **MAE** | Robuste aux outliers | Quand outliers dans les erreurs |
| **RÂ²** | Proportion de variance expliquÃ©e | Comparaison de modÃ¨les |
| **MAPE** | Erreur en pourcentage | Quand Ã©chelles variables |

---

## Phase 6 : DÃ©ploiement

### Checklist de DÃ©ploiement

- [ ] **SÃ©rialiser le modÃ¨le**
  ```python
  import joblib
  joblib.dump(model, 'model.pkl')
  # ou
  import pickle
  with open('model.pkl', 'wb') as f:
      pickle.dump(model, f)
  ```

- [ ] **CrÃ©er une API** (Flask/FastAPI)
- [ ] **Dockeriser l'application**
- [ ] **Tests unitaires**
- [ ] **CI/CD pipeline**
- [ ] **Monitoring des performances**
- [ ] **Logging des prÃ©dictions**
- [ ] **Gestion des versions**
- [ ] **Documentation**

---

## Questions Critiques Ã  se Poser

### Avant de Commencer

1. **Le ML est-il nÃ©cessaire ?**
   - Peut-on rÃ©soudre avec des rÃ¨gles simples ?
   - Y a-t-il assez de donnÃ©es ?
   - Le ROI justifie-t-il l'investissement ?

2. **Les donnÃ©es sont-elles de qualitÃ© ?**
   - ReprÃ©sentatives de la population cible ?
   - RÃ©centes et Ã  jour ?
   - Suffisamment volumineuses ?
   - Bien labelisÃ©es (supervisÃ©) ?

3. **Le problÃ¨me est-il bien dÃ©fini ?**
   - Objectifs clairs et mesurables ?
   - CritÃ¨res de succÃ¨s dÃ©finis ?
   - Contraintes identifiÃ©es ?

### Pendant le Projet

4. **Le modÃ¨le apprend-il correctement ?**
   - Overfitting ? (train >> val)
   - Underfitting ? (train et val faibles)
   - Convergence atteinte ?

5. **Les performances sont-elles suffisantes ?**
   - Meilleures que la baseline ?
   - Atteignent les objectifs ?
   - GÃ©nÃ©ralisent sur nouvelles donnÃ©es ?

6. **Le modÃ¨le est-il interprÃ©table ?**
   - Features importantes identifiÃ©es ?
   - PrÃ©dictions expliquables ?
   - Confiance dans les prÃ©dictions ?

### Avant DÃ©ploiement

7. **Le modÃ¨le est-il robuste ?**
   - TestÃ© sur cas limites ?
   - GÃ¨re les donnÃ©es manquantes ?
   - Stable dans le temps ?

8. **Le systÃ¨me est-il prÃªt ?**
   - Infrastructure scalable ?
   - Monitoring en place ?
   - Plan de maintenance dÃ©fini ?

---

## Templates de Documentation

### Template de Rapport de Projet

```markdown
# Rapport Projet ML : [Nom du Projet]

## 1. RÃ©sumÃ© ExÃ©cutif
- ProblÃ©matique : [...]
- Solution : [...]
- RÃ©sultats : [...]
- Impact : [...]

## 2. Contexte et Objectifs
### 2.1 Contexte
[Description du contexte mÃ©tier]

### 2.2 ProblÃ©matique
[ProblÃ¨me Ã  rÃ©soudre]

### 2.3 Objectifs
- Objectif principal : [...]
- Objectifs secondaires : [...]
- CritÃ¨res de succÃ¨s : [...]

## 3. DonnÃ©es
### 3.1 Sources
[Sources de donnÃ©es utilisÃ©es]

### 3.2 Description
- Volume : [...]
- PÃ©riode : [...]
- Features : [...]

### 3.3 QualitÃ©
- Valeurs manquantes : [...]
- Outliers : [...]
- Distribution : [...]

## 4. MÃ©thodologie
### 4.1 PrÃ©paration des DonnÃ©es
[Ã‰tapes de preprocessing]

### 4.2 Feature Engineering
[Features crÃ©Ã©es]

### 4.3 ModÃ©lisation
- ModÃ¨les testÃ©s : [...]
- ModÃ¨le sÃ©lectionnÃ© : [...]
- HyperparamÃ¨tres : [...]

## 5. RÃ©sultats
### 5.1 Performances
- MÃ©trique principale : [...]
- MÃ©triques secondaires : [...]
- Comparaison baseline : [...]

### 5.2 Analyse
[Analyse des rÃ©sultats, features importantes, etc.]

## 6. DÃ©ploiement
### 6.1 Architecture
[SchÃ©ma de dÃ©ploiement]

### 6.2 Monitoring
[MÃ©triques suivies]

## 7. Conclusion et Recommandations
### 7.1 Conclusion
[SynthÃ¨se]

### 7.2 Limitations
[Limitations identifiÃ©es]

### 7.3 Perspectives
[AmÃ©liorations futures]
```

---

## Checklist Finale

### Avant de Valider le Projet

- [ ] ProblÃ©matique claire et objectifs dÃ©finis
- [ ] DonnÃ©es collectÃ©es et analysÃ©es
- [ ] EDA complÃ©tÃ©e
- [ ] Preprocessing et feature engineering documentÃ©s
- [ ] Plusieurs modÃ¨les testÃ©s
- [ ] Baseline dÃ©passÃ©e
- [ ] HyperparamÃ¨tres optimisÃ©s
- [ ] Cross-validation effectuÃ©e
- [ ] Ã‰valuation sur test set
- [ ] Analyse des erreurs
- [ ] Features importantes identifiÃ©es
- [ ] ModÃ¨le sÃ©rialisÃ©
- [ ] Documentation complÃ¨te
- [ ] Code versionnÃ© (git)
- [ ] Tests unitaires
- [ ] Rapport de projet rÃ©digÃ©

---

**ğŸ¯ Avec ce guide, vous avez toutes les clÃ©s pour mener Ã  bien un projet ML de A Ã  Z !**

---

**Navigation :**
- [â¡ï¸ Guide de DÃ©cision ML](00_Guide_Decision_ML.md)
- [â¡ï¸ Workflows ML](00_Workflows_ML.md)
- [ğŸ  Retour au Sommaire](README.md)
