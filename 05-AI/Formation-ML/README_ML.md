# Formation ComplÃ¨te en Machine Learning

## ğŸ“š Ã€ Propos

Cette formation complÃ¨te en Machine Learning a Ã©tÃ© crÃ©Ã©e Ã  partir de mes notes des cours magistraux et travaux pratiques de mon Master. Elle combine thÃ©orie mathÃ©matique et pratique Python pour une comprÃ©hension approfondie du Machine Learning et du Deep Learning.

## ğŸ¯ Objectifs PÃ©dagogiques

Ã€ l'issue de cette formation, vous serez capable de :

- MaÃ®triser les fondamentaux mathÃ©matiques du Machine Learning
- Manipuler et visualiser des donnÃ©es avec Python (NumPy, Pandas, Matplotlib)
- ImplÃ©menter des modÃ¨les de Machine Learning supervisÃ© et non supervisÃ©
- Concevoir et entraÃ®ner des rÃ©seaux de neurones profonds
- Appliquer les techniques de Deep Learning (CNN, rÃ©seaux profonds)
- Ã‰valuer et optimiser les performances des modÃ¨les

## ğŸ“– Structure de la Formation

### Module 1 : [Introduction et Motivation](01_Introduction_et_Motivation.md)

- DÃ©finition du Machine Learning
- Applications concrÃ¨tes (reconnaissance d'images, NLP, prÃ©visions)
- Types d'apprentissage (supervisÃ©, non supervisÃ©, par renforcement)
- Environnement de travail Python

### Module 2 : [AlgÃ¨bre LinÃ©aire](02_Algebre_Lineaire.md)

- Vecteurs et matrices
- OpÃ©rations matricielles
- Valeurs et vecteurs propres
- Projections orthogonales
- DÃ©composition SVD

### Module 3 : [ProbabilitÃ©s](03_Probabilites.md)

- ThÃ©orie des probabilitÃ©s
- Variables alÃ©atoires
- Lois de probabilitÃ© courantes
- ThÃ©orÃ¨me de Bayes
- EspÃ©rance et variance

### Module 4 : [Statistiques Descriptives](04_Statistiques_Descriptives.md)

- Mesures de tendance centrale
- Mesures de dispersion
- Visualisation de donnÃ©es
- CorrÃ©lation et rÃ©gression linÃ©aire
- Analyse exploratoire des donnÃ©es

### Module 5 : [Optimisation NumÃ©rique](05_Optimisation_Numerique.md)

- Gradient et dÃ©rivÃ©es
- Descente de gradient
- MÃ©thodes d'optimisation (SGD, Adam, RMSprop)
- Convergence et taux d'apprentissage
- Optimisation sous contraintes

### Module 6 : [Apprentissage SupervisÃ©](06_Apprentissage_Supervise.md)

- RÃ©gression linÃ©aire et logistique
- Arbres de dÃ©cision
- ForÃªts alÃ©atoires
- SVM (Support Vector Machines)
- Ã‰valuation des modÃ¨les (accuracy, prÃ©cision, recall, F1-score)

### Module 7 : [RÃ©seaux de Neurones Profonds](07_Reseaux_Neurones_Profonds.md)

- Perceptron et perceptron multicouche
- Fonction d'activation
- Backpropagation
- RÃ©gularisation (Dropout, L1/L2)
- Batch Normalization

### Module 8 : [RÃ©seaux de Neurones Convolutifs (CNN)](08_CNN.md)

- Couches de convolution
- Pooling
- Architectures cÃ©lÃ¨bres (LeNet, AlexNet, VGG, ResNet)
- Transfer Learning
- Applications en vision par ordinateur

### Module 9 : [Apprentissage Non SupervisÃ©](09_Apprentissage_Non_Supervise.md)

- Clustering (K-means, DBSCAN, clustering hiÃ©rarchique)
- RÃ©duction de dimensionnalitÃ© (PCA, t-SNE)
- Autoencodeurs
- DÃ©tection d'anomalies
- Apprentissage par renforcement (introduction)

---

## ğŸ“˜ Guides Pratiques et MÃ©thodologiques

### [Guide Complet : DÃ©marrer un Projet ML](00_Guide_Projet_ML.md)

**Checklist complÃ¨te pour mener un projet ML de A Ã  Z**

- âœ… Checklist des 6 phases (ComprÃ©hension â†’ DÃ©ploiement)
- ğŸ“‹ Questions critiques Ã  se poser
- ğŸ“Š Scripts d'exploration de donnÃ©es (EDA)
- ğŸ”§ StratÃ©gies de traitement des donnÃ©es
- ğŸ“ˆ Feature engineering
- ğŸ¯ Validation et Ã©valuation
- ğŸ“ Templates de documentation

### [Guide de DÃ©cision : Quel ModÃ¨le ML pour Quel ProblÃ¨me ?](00_Guide_Decision_ML.md)

**Arbre de dÃ©cision pour choisir le bon modÃ¨le**

- ğŸŒ³ Arbres de dÃ©cision par type de problÃ¨me
- ğŸ“Š Tableaux comparatifs dÃ©taillÃ©s
- ğŸ” Quand utiliser chaque modÃ¨le (avantages/inconvÃ©nients)
- âš™ï¸ Guide des techniques d'optimisation
- ğŸ’¡ Ã€ quoi sert la descente de gradient ?
- ğŸ¯ Exemples de code pour chaque modÃ¨le

**Contenu dÃ©taillÃ© :**

- Classification (Logistic Regression, Decision Tree, Random Forest, XGBoost, SVM, Naive Bayes, KNN)
- RÃ©gression (Linear, Ridge, Lasso, ElasticNet, Random Forest, XGBoost)
- Clustering (K-Means, DBSCAN, HiÃ©rarchique, Gaussian Mixture)
- RÃ©duction de dimensionnalitÃ© (PCA, t-SNE, UMAP, Autoencoders)

### [Workflows ML : Construire, Optimiser, Valider et Tester](00_Workflows_ML.md)

**Diagrammes et workflows Ã©tape par Ã©tape**

- ğŸ”„ Workflow complet d'un projet ML
- ğŸ—ï¸ Construction d'un modÃ¨le (code complet)
- âš¡ Optimisation (Grid Search, Random Search, diagnostics)
- âœ… Validation (K-Fold, Stratified, Time Series Split)
- ğŸ§  Workflow Deep Learning spÃ©cifique
- ğŸš€ Pipeline de production
- ğŸ”§ RÃ©solution de problÃ¨mes (overfitting/underfitting)

---

## ğŸ’» Tutoriels Pratiques DÃ©taillÃ©s

### Dossier [TUTORIELS/](TUTORIELS/)

**Tutoriels complets en Python avec explications dÃ©taillÃ©es de chaque Ã©tape, paramÃ¨tre et fonction.**

#### âœ… Disponible :

- **[Tuto_01_Regression_Lineaire.py](TUTORIELS/Tuto_01_Regression_Lineaire.py)**
  - RÃ©gression linÃ©aire simple (OLS)
  - Ridge Regression (L2)
  - Lasso Regression (L1)
  - Cross-validation
  - Analyse des rÃ©sidus
  - Feature importance
  - Visualisations complÃ¨tes
  - **~800 lignes de code commentÃ©**

#### ğŸ”œ Ã€ venir :

- Classification (Logistic Regression, Trees, Random Forest, XGBoost)
- RÃ©seaux de neurones (Dense networks, optimisation)
- CNN pour images
- Clustering et non-supervisÃ©

**Format des tutoriels :**

1. ThÃ©orie et formules mathÃ©matiques
2. PrÃ©paration des donnÃ©es
3. EntraÃ®nement du modÃ¨le
4. Optimisation des hyperparamÃ¨tres
5. Validation et cross-validation
6. Ã‰valuation finale
7. InterprÃ©tation et diagnostics
8. Sauvegarde du modÃ¨le

---

## ğŸ› ï¸ PrÃ©requis Techniques

### Logiciels

- **Python 3.7+** (recommandÃ© : Python 3.10+)
- **Anaconda** ou **Miniconda**
- **Jupyter Notebook** ou **JupyterLab**

### BibliothÃ¨ques Python Essentielles

```bash
pip install numpy pandas matplotlib seaborn scikit-learn tensorflow keras
```

#### Manipulation de donnÃ©es

- **NumPy** : Calcul numÃ©rique et manipulation de tableaux
- **Pandas** : Manipulation et analyse de donnÃ©es
- **Matplotlib** : Visualisation de base
- **Seaborn** : Visualisation statistique avancÃ©e

#### Machine Learning

- **Scikit-learn** : Algorithmes de ML classiques
- **TensorFlow** : Framework de Deep Learning
- **Keras** : API haut niveau pour rÃ©seaux de neurones

## ğŸ“š Ressources ComplÃ©mentaires

### Livres de RÃ©fÃ©rence

1. **"The Elements of Statistical Learning"** - Hastie, Tibshirani, Friedman
2. **"Pattern Recognition and Machine Learning"** - Christopher Bishop
3. **"Machine Learning: A Probabilistic Perspective"** - Kevin Murphy
4. **"Deep Learning"** - Goodfellow, Bengio, Courville
5. **"Reinforcement Learning: An Introduction"** - Sutton & Barto

### Cours en Ligne

- [Machine Learning - Andrew Ng (Coursera)](https://www.coursera.org/learn/machine-learning)
- [Deep Learning Specialization - Andrew Ng](https://www.coursera.org/specializations/deep-learning)
- [Reinforcement Learning - David Silver (UCL)](https://www.davidsilver.uk/teaching/)

### Plateformes Pratiques

- [Kaggle](https://www.kaggle.com/) - CompÃ©titions et datasets
- [Towards Data Science](https://towardsdatascience.com/) - Articles techniques
- [Papers with Code](https://paperswithcode.com/) - Papiers de recherche avec implÃ©mentations

## ğŸ“ Ã‰valuation et Pratique

Chaque module contient :

- âœ… **ThÃ©orie** : Concepts mathÃ©matiques et fondamentaux
- ğŸ’» **Exemples pratiques** : Code Python commentÃ©
- ğŸ”§ **Exercices** : Applications concrÃ¨tes avec solutions
- ğŸ“ **RÃ©sumÃ©** : Points clÃ©s Ã  retenir

## ğŸš€ Comment Utiliser Cette Formation

1. **Parcours LinÃ©aire** : Suivez les modules dans l'ordre pour une progression cohÃ©rente
2. **Parcours ThÃ©matique** : Consultez directement les modules qui vous intÃ©ressent
3. **Pratique Intensive** : ExÃ©cutez tous les exemples de code dans Jupyter Notebook
4. **Projets Personnels** : Appliquez les concepts sur vos propres donnÃ©es

## ğŸ“„ Licence

Ce matÃ©riel pÃ©dagogique est destinÃ© Ã  un usage Ã©ducatif.

---

**Bon apprentissage ! ğŸ‰**
