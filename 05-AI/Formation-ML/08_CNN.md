# Module 8 : R√©seaux de Neurones Convolutifs (CNN)

## üìã Table des Mati√®res

1. [Introduction](#introduction)
2. [Limites des MLP pour les Images](#limites-des-mlp-pour-les-images)
3. [Op√©ration de Convolution](#op√©ration-de-convolution)
4. [Pooling](#pooling)
5. [Architecture Compl√®te d'un CNN](#architecture-compl√®te-dun-cnn)
6. [Architectures C√©l√®bres](#architectures-c√©l√®bres)
7. [Transfer Learning](#transfer-learning)
8. [Impl√©mentation Pratique](#impl√©mentation-pratique)
9. [Projet : Classification d'Images](#projet--classification-dimages)
10. [R√©sum√©](#r√©sum√©)

---

## Introduction

Les **R√©seaux de Neurones Convolutifs** (Convolutional Neural Networks, CNN) sont sp√©cialis√©s pour le traitement de donn√©es structur√©es en grille, notamment les **images**.

### Pourquoi les CNN ?

**R√©volutions** :

- **2012** : AlexNet gagne ImageNet (classification d'images)
- **Vision par ordinateur** : State-of-the-art sur reconnaissance, d√©tection, segmentation
- **Applications** : Voitures autonomes, diagnostic m√©dical, reconnaissance faciale

### Applications

| T√¢che                  | Description                   | Exemples           |
| ---------------------- | ----------------------------- | ------------------ |
| **Classification**     | Quelle est la classe ?        | ImageNet, CIFAR-10 |
| **D√©tection d'objets** | O√π sont les objets ?          | YOLO, Faster R-CNN |
| **Segmentation**       | D√©limiter chaque pixel        | U-Net, Mask R-CNN  |
| **Style Transfer**     | Appliquer un style artistique | DeepArt            |
| **Super-r√©solution**   | Am√©liorer la r√©solution       | SRGAN              |

```python
import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers

print(f"TensorFlow version: {tf.__version__}")
```

---

## Limites des MLP pour les Images

### Probl√®mes avec MLP

Consid√©rons une image $32 \times 32$ RGB :

- **Dimensions** : $32 \times 32 \times 3 = 3072$ pixels
- **Fully connected** : Chaque neurone connect√© √† tous les pixels

**Inconv√©nients** :

1. **Nombre de param√®tres explosif** :

   - Premi√®re couche (1000 neurones) : $3072 \times 1000 = 3\,000\,000$ poids
   - Pour image $224 \times 224$ : $150\,528 \times 1000 = 150\,000\,000$ poids !

2. **Perte de structure spatiale** :

   - MLP traite l'image comme un vecteur 1D
   - Ignore la proximit√© des pixels

3. **Pas d'invariance** :
   - Un objet d√©cal√© est consid√©r√© comme diff√©rent

### Solution : CNN

**Principes** :

- **Connectivit√© locale** : Chaque neurone connect√© √† une petite r√©gion
- **Partage de poids** : M√™me filtre appliqu√© sur toute l'image
- **Hi√©rarchie** : Features simples ‚Üí Features complexes

```python
# Exemple de dimensions
print("MLP sur image 224√ó224 RGB:")
print(f"  Input: {224*224*3} = 150,528 features")
print(f"  Premi√®re couche dense (1000 neurones): {150_528 * 1000:,} poids")

print("\nCNN sur m√™me image:")
print(f"  Input: (224, 224, 3)")
print(f"  Conv2D(32 filters, 3√ó3): {3*3*3*32 + 32} = 896 poids")
print(f"  R√©duction de facteur: {150_528_000 / 896:.0f}x !")
```

---

## Op√©ration de Convolution

### Principe

La **convolution** applique un **filtre** (kernel) sur l'image pour d√©tecter des features locales.

### Formule Math√©matique

Pour une image $I$ et un filtre $K$ de taille $k \times k$ :

$$
(I * K)(i, j) = \sum_{m=0}^{k-1} \sum_{n=0}^{k-1} I(i+m, j+n) \cdot K(m, n)
$$

### Exemple Visuel

```
Image (5√ó5):          Filtre (3√ó3):       Output (3√ó3):
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 1 2 1 0 1   ‚îÇ      ‚îÇ 1 0 1 ‚îÇ           ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 0 1 2 1 0   ‚îÇ  *   ‚îÇ 0 1 0 ‚îÇ    ‚Üí      ‚îÇ a b c ‚îÇ
‚îÇ 1 0 1 0 1   ‚îÇ      ‚îÇ 1 0 1 ‚îÇ           ‚îÇ d e f ‚îÇ
‚îÇ 2 1 0 1 2   ‚îÇ      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò           ‚îÇ g h i ‚îÇ
‚îÇ 1 0 1 2 1   ‚îÇ                          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

Calcul de 'e' (centre):
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 1 2 ‚îÇ √ó ‚îÇ 1 0 1 ‚îÇ = 1√ó1 + 2√ó0 + 1√ó1 + 0√ó0 + 1√ó1 + 0√ó0 + 1√ó1 + 0√ó0 + 1√ó1 = 5
‚îÇ 0 1 ‚îÇ   ‚îÇ 0 1 0 ‚îÇ
‚îÇ 1 0 ‚îÇ   ‚îÇ 1 0 1 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Impl√©mentation NumPy

```python
def conv2d_simple(image, kernel):
    """Convolution 2D simple (sans padding)"""
    h, w = image.shape
    kh, kw = kernel.shape
    output_h = h - kh + 1
    output_w = w - kw + 1
    output = np.zeros((output_h, output_w))

    for i in range(output_h):
        for j in range(output_w):
            region = image[i:i+kh, j:j+kw]
            output[i, j] = np.sum(region * kernel)

    return output

# Exemple
image = np.array([
    [1, 2, 1, 0, 1],
    [0, 1, 2, 1, 0],
    [1, 0, 1, 0, 1],
    [2, 1, 0, 1, 2],
    [1, 0, 1, 2, 1]
], dtype=np.float32)

# Filtre de d√©tection de bords (Sobel horizontal)
kernel = np.array([
    [1, 0, -1],
    [2, 0, -2],
    [1, 0, -1]
], dtype=np.float32)

result = conv2d_simple(image, kernel)

# Visualisation
fig, axes = plt.subplots(1, 3, figsize=(12, 4))

axes[0].imshow(image, cmap='gray')
axes[0].set_title('Image Originale')
axes[0].axis('off')

axes[1].imshow(kernel, cmap='gray')
axes[1].set_title('Filtre (Kernel)')
axes[1].axis('off')

axes[2].imshow(result, cmap='gray')
axes[2].set_title('Apr√®s Convolution')
axes[2].axis('off')

plt.tight_layout()
plt.show()
```

### Hyperparam√®tres de Convolution

#### 1. Padding

**Probl√®me** : La taille de l'output diminue.

**Solution** : Ajouter des z√©ros autour de l'image.

- **Valid** : Pas de padding ‚Üí taille r√©duite
- **Same** : Padding pour garder m√™me taille

$$
\text{Output size} = \frac{n + 2p - f}{s} + 1
$$

o√π :

- $n$ : taille de l'input
- $p$ : padding
- $f$ : taille du filtre
- $s$ : stride

```python
# Keras/TensorFlow
layers.Conv2D(32, (3, 3), padding='same')   # Garde taille
layers.Conv2D(32, (3, 3), padding='valid')  # R√©duit taille
```

#### 2. Stride

**Stride** : Nombre de pixels dont on d√©cale le filtre.

- **Stride = 1** : D√©placement pixel par pixel
- **Stride = 2** : On saute un pixel ‚Üí r√©duit taille par 2

```python
layers.Conv2D(64, (3, 3), strides=2)  # Stride = 2
```

#### 3. Nombre de Filtres

Chaque filtre d√©tecte une feature diff√©rente.

```python
layers.Conv2D(64, (3, 3))  # 64 filtres = 64 feature maps en sortie
```

### Filtres Classiques

```python
# Exemples de filtres
import numpy as np
import matplotlib.pyplot as plt

filtres = {
    'Identit√©': np.array([[0, 0, 0],
                           [0, 1, 0],
                           [0, 0, 0]]),

    'Bords Horizontal': np.array([[ 1,  2,  1],
                                   [ 0,  0,  0],
                                   [-1, -2, -1]]),

    'Bords Vertical': np.array([[1, 0, -1],
                                 [2, 0, -2],
                                 [1, 0, -1]]),

    'Flou': np.array([[1, 1, 1],
                       [1, 1, 1],
                       [1, 1, 1]]) / 9,

    'Sharpen': np.array([[ 0, -1,  0],
                          [-1,  5, -1],
                          [ 0, -1,  0]])
}

# Charger une image exemple
from tensorflow.keras.preprocessing import image as keras_image
from tensorflow.keras.applications.vgg16 import preprocess_input

# Ou cr√©er une image simple
img = np.random.rand(100, 100)

# Appliquer chaque filtre
fig, axes = plt.subplots(2, 3, figsize=(15, 10))
axes = axes.ravel()

axes[0].imshow(img, cmap='gray')
axes[0].set_title('Image Originale')
axes[0].axis('off')

for idx, (name, kernel) in enumerate(filtres.items(), 1):
    result = conv2d_simple(img, kernel)
    axes[idx].imshow(result, cmap='gray')
    axes[idx].set_title(name)
    axes[idx].axis('off')

plt.tight_layout()
plt.show()
```

---

## Pooling

Le **pooling** r√©duit la dimensionnalit√© spatiale tout en conservant les features importantes.

### Max Pooling

Prendre le **maximum** dans chaque r√©gion.

```
Input (4√ó4):          Max Pool 2√ó2:    Output (2√ó2):
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      (stride=2)
‚îÇ 1 3 2 4 ‚îÇ                         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 5 6 7 8 ‚îÇ      ‚Üí                  ‚îÇ 6 8 ‚îÇ
‚îÇ 9 2 1 3 ‚îÇ                         ‚îÇ 9 7 ‚îÇ
‚îÇ 4 5 7 2 ‚îÇ                         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Avantages** :

- R√©duit le calcul
- Invariance aux petites translations
- Conserve les features les plus fortes

### Average Pooling

Prendre la **moyenne** dans chaque r√©gion.

### Impl√©mentation

```python
from tensorflow.keras.layers import MaxPooling2D, AveragePooling2D

# Max Pooling
layers.MaxPooling2D(pool_size=(2, 2), strides=2)

# Average Pooling
layers.AveragePooling2D(pool_size=(2, 2))
```

### Comparaison

```python
# Exemple
input_data = np.array([[
    [1, 3, 2, 4],
    [5, 6, 7, 8],
    [9, 2, 1, 3],
    [4, 5, 7, 2]
]], dtype=np.float32)

input_tensor = tf.constant(input_data.reshape(1, 4, 4, 1))

# Max Pooling
max_pool = tf.nn.max_pool2d(input_tensor, ksize=2, strides=2, padding='VALID')
print("Max Pooling:\n", max_pool.numpy().squeeze())

# Average Pooling
avg_pool = tf.nn.avg_pool2d(input_tensor, ksize=2, strides=2, padding='VALID')
print("\nAverage Pooling:\n", avg_pool.numpy().squeeze())
```

---

## Architecture Compl√®te d'un CNN

### Structure Typique

```
Input Image (H√óW√óC)
    ‚Üì
[Conv ‚Üí ReLU ‚Üí Conv ‚Üí ReLU ‚Üí MaxPool] √ó N
    ‚Üì
Flatten
    ‚Üì
[Dense ‚Üí ReLU ‚Üí Dropout] √ó M
    ‚Üì
Dense (Softmax pour classification)
    ‚Üì
Output (Classes)
```

### Exemple Concret

```python
from tensorflow.keras import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout

model = Sequential([
    # Block 1
    Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(28, 28, 1)),
    Conv2D(32, (3, 3), activation='relu', padding='same'),
    MaxPooling2D((2, 2)),

    # Block 2
    Conv2D(64, (3, 3), activation='relu', padding='same'),
    Conv2D(64, (3, 3), activation='relu', padding='same'),
    MaxPooling2D((2, 2)),

    # Block 3
    Conv2D(128, (3, 3), activation='relu', padding='same'),
    MaxPooling2D((2, 2)),

    # Classifier
    Flatten(),
    Dense(256, activation='relu'),
    Dropout(0.5),
    Dense(10, activation='softmax')
])

model.compile(
    optimizer='adam',
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

print(model.summary())
```

### √âvolution des Dimensions

```
Input:  (28, 28, 1)
    ‚Üì
Conv2D(32, 3√ó3, same):  (28, 28, 32)
Conv2D(32, 3√ó3, same):  (28, 28, 32)
MaxPool(2√ó2):           (14, 14, 32)
    ‚Üì
Conv2D(64, 3√ó3, same):  (14, 14, 64)
Conv2D(64, 3√ó3, same):  (14, 14, 64)
MaxPool(2√ó2):           (7, 7, 64)
    ‚Üì
Conv2D(128, 3√ó3, same): (7, 7, 128)
MaxPool(2√ó2):           (3, 3, 128)
    ‚Üì
Flatten:                (1152,)  # 3√ó3√ó128
Dense(256):             (256,)
Dense(10):              (10,)
```

---

## Architectures C√©l√®bres

### 1. LeNet-5 (1998)

**Premi√®re architecture CNN** par Yann LeCun pour reconnaissance de chiffres.

```python
def LeNet5():
    model = Sequential([
        Conv2D(6, (5, 5), activation='tanh', input_shape=(28, 28, 1)),
        AveragePooling2D((2, 2)),
        Conv2D(16, (5, 5), activation='tanh'),
        AveragePooling2D((2, 2)),
        Flatten(),
        Dense(120, activation='tanh'),
        Dense(84, activation='tanh'),
        Dense(10, activation='softmax')
    ])
    return model
```

### 2. AlexNet (2012)

**R√©volution ImageNet** - Premi√®re victoire d'un CNN profond.

**Innovations** :

- ReLU (au lieu de Tanh)
- Dropout
- Data Augmentation
- GPU Training

**Architecture** :

- 5 couches convolutives
- 3 couches fully connected
- 60 millions de param√®tres

### 3. VGG-16 (2014)

**Principe** : Profondeur + petits filtres (3√ó3)

```python
from tensorflow.keras.applications import VGG16

vgg = VGG16(weights='imagenet', include_top=True, input_shape=(224, 224, 3))
print(vgg.summary())
```

**Caract√©ristiques** :

- 16 couches avec poids
- Filtres 3√ó3 uniquement
- MaxPool apr√®s chaque bloc
- 138 millions de param√®tres

**Architecture** :

```
64 ‚Üí 64 ‚Üí MaxPool ‚Üí
128 ‚Üí 128 ‚Üí MaxPool ‚Üí
256 ‚Üí 256 ‚Üí 256 ‚Üí MaxPool ‚Üí
512 ‚Üí 512 ‚Üí 512 ‚Üí MaxPool ‚Üí
512 ‚Üí 512 ‚Üí 512 ‚Üí MaxPool ‚Üí
FC ‚Üí FC ‚Üí FC (4096 ‚Üí 4096 ‚Üí 1000)
```

### 4. ResNet (2015)

**Innovation** : **Residual Connections** (Skip Connections)

**Probl√®me** : R√©seaux tr√®s profonds difficiles √† entra√Æner (vanishing gradients)

**Solution** : Connexions r√©siduelles

$$
\mathbf{y} = F(\mathbf{x}) + \mathbf{x}
$$

```python
from tensorflow.keras.applications import ResNet50

resnet = ResNet50(weights='imagenet', include_top=True, input_shape=(224, 224, 3))
```

**Variantes** :

- ResNet-18, ResNet-34, ResNet-50, ResNet-101, ResNet-152

**Impact** : Permet de construire des r√©seaux tr√®s profonds (>100 couches)

### 5. Inception (GoogLeNet, 2014)

**Principe** : **Modules Inception** - convolutions parall√®les de diff√©rentes tailles.

```
Input
  ‚îú‚îÄ 1√ó1 Conv
  ‚îú‚îÄ 1√ó1 Conv ‚Üí 3√ó3 Conv
  ‚îú‚îÄ 1√ó1 Conv ‚Üí 5√ó5 Conv
  ‚îî‚îÄ 3√ó3 MaxPool ‚Üí 1√ó1 Conv
  ‚Üì
Concatenate
```

**Avantage** : Capture features √† diff√©rentes √©chelles

```python
from tensorflow.keras.applications import InceptionV3

inception = InceptionV3(weights='imagenet', include_top=True, input_shape=(299, 299, 3))
```

### Comparaison

| Architecture    | Ann√©e | Profondeur | Param√®tres | Top-5 Error (ImageNet) |
| --------------- | ----- | ---------- | ---------- | ---------------------- |
| LeNet-5         | 1998  | 7          | 60K        | -                      |
| AlexNet         | 2012  | 8          | 60M        | 16.4%                  |
| VGG-16          | 2014  | 16         | 138M       | 7.3%                   |
| GoogLeNet       | 2014  | 22         | 4M         | 6.7%                   |
| ResNet-152      | 2015  | 152        | 60M        | 3.57%                  |
| EfficientNet-B7 | 2019  | -          | 66M        | 2.9%                   |

---

## Transfer Learning

**Principe** : Utiliser un mod√®le pr√©-entra√Æn√© et l'adapter √† une nouvelle t√¢che.

### Pourquoi Transfer Learning ?

**Avantages** :

- **Moins de donn√©es** n√©cessaires
- **Entra√Ænement plus rapide**
- **Meilleures performances** (features g√©n√©riques d√©j√† apprises)

**Cas d'usage** :

- Dataset petit (<10,000 images)
- Ressources de calcul limit√©es
- Domaine proche d'ImageNet (objets, sc√®nes)

### Strat√©gies

#### 1. Feature Extractor (Frozen)

Utiliser le mod√®le comme **extracteur de features** fixe.

```python
from tensorflow.keras.applications import VGG16
from tensorflow.keras import Sequential
from tensorflow.keras.layers import Dense, Flatten, Dropout

# Charger mod√®le pr√©-entra√Æn√© (sans le top)
base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))

# Geler les poids
base_model.trainable = False

# Ajouter classifier personnalis√©
model = Sequential([
    base_model,
    Flatten(),
    Dense(256, activation='relu'),
    Dropout(0.5),
    Dense(10, activation='softmax')  # 10 classes
])

model.compile(
    optimizer='adam',
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

print(model.summary())
```

#### 2. Fine-Tuning

D√©geler et r√©entra√Æner les derni√®res couches.

```python
# D'abord entra√Æner avec base frozen
model.fit(X_train, y_train, epochs=5)

# Puis d√©geler les derni√®res couches
base_model.trainable = True

# Geler seulement les premi√®res couches
for layer in base_model.layers[:-4]:
    layer.trainable = False

# Recompiler avec learning rate plus faible
model.compile(
    optimizer=keras.optimizers.Adam(learning_rate=1e-5),  # LR plus faible
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

# Fine-tune
model.fit(X_train, y_train, epochs=10)
```

### Exemple Complet : Classification Chats vs Chiens

```python
from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras.preprocessing.image import ImageDataGenerator

# 1. Mod√®le pr√©-entra√Æn√©
base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))
base_model.trainable = False

# 2. Ajouter classifier
model = Sequential([
    base_model,
    layers.GlobalAveragePooling2D(),
    layers.Dense(128, activation='relu'),
    layers.Dropout(0.5),
    layers.Dense(1, activation='sigmoid')  # Binaire : chat (0) ou chien (1)
])

# 3. Compiler
model.compile(
    optimizer='adam',
    loss='binary_crossentropy',
    metrics=['accuracy']
)

# 4. Data Augmentation
train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    horizontal_flip=True,
    validation_split=0.2
)

# 5. Charger donn√©es
train_generator = train_datagen.flow_from_directory(
    'data/cats_dogs/',
    target_size=(224, 224),
    batch_size=32,
    class_mode='binary',
    subset='training'
)

val_generator = train_datagen.flow_from_directory(
    'data/cats_dogs/',
    target_size=(224, 224),
    batch_size=32,
    class_mode='binary',
    subset='validation'
)

# 6. Entra√Æner
history = model.fit(
    train_generator,
    validation_data=val_generator,
    epochs=10
)
```

---

## Impl√©mentation Pratique

### Pr√©traitement d'Images

```python
from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array

# 1. Chargement
img = load_img('image.jpg', target_size=(224, 224))
img_array = img_to_array(img)  # (224, 224, 3)
img_array = np.expand_dims(img_array, axis=0)  # (1, 224, 224, 3)

# 2. Normalisation
img_array = img_array / 255.0  # [0, 1]

# 3. Pr√©traitement sp√©cifique au mod√®le
from tensorflow.keras.applications.vgg16 import preprocess_input
img_preprocessed = preprocess_input(img_array)
```

### Data Augmentation

```python
datagen = ImageDataGenerator(
    rotation_range=40,        # Rotation al√©atoire ¬±40¬∞
    width_shift_range=0.2,    # D√©calage horizontal ¬±20%
    height_shift_range=0.2,   # D√©calage vertical ¬±20%
    shear_range=0.2,          # Cisaillement
    zoom_range=0.2,           # Zoom ¬±20%
    horizontal_flip=True,     # Flip horizontal
    fill_mode='nearest'       # Remplissage des pixels
)

# G√©n√©rer des images augment√©es
for X_batch, y_batch in datagen.flow(X_train, y_train, batch_size=32):
    # Entra√Æner sur batch augment√©
    model.fit(X_batch, y_batch)
```

### Visualisation des Features Maps

```python
from tensorflow.keras import Model

# Cr√©er mod√®le pour extraire features interm√©diaires
layer_outputs = [layer.output for layer in model.layers[:8]]
activation_model = Model(inputs=model.input, outputs=layer_outputs)

# Pr√©dire
activations = activation_model.predict(img_array)

# Visualiser premi√®re couche Conv
first_layer_activation = activations[0]

plt.figure(figsize=(15, 15))
for i in range(min(32, first_layer_activation.shape[-1])):
    plt.subplot(6, 6, i+1)
    plt.imshow(first_layer_activation[0, :, :, i], cmap='viridis')
    plt.axis('off')
plt.suptitle('Feature Maps - Premi√®re Couche Conv')
plt.show()
```

---

## Projet : Classification d'Images

### CIFAR-10 Classification

```python
from tensorflow.keras.datasets import cifar10
from tensorflow.keras.utils import to_categorical
from tensorflow.keras import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau

# 1. Charger donn√©es
(X_train, y_train), (X_test, y_test) = cifar10.load_data()

# Classes
class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',
               'dog', 'frog', 'horse', 'ship', 'truck']

print(f"X_train shape: {X_train.shape}")  # (50000, 32, 32, 3)
print(f"X_test shape: {X_test.shape}")    # (10000, 32, 32, 3)

# Visualiser quelques images
plt.figure(figsize=(12, 6))
for i in range(20):
    plt.subplot(4, 5, i+1)
    plt.imshow(X_train[i])
    plt.title(class_names[y_train[i][0]])
    plt.axis('off')
plt.tight_layout()
plt.show()

# 2. Pr√©traitement
X_train = X_train.astype('float32') / 255.0
X_test = X_test.astype('float32') / 255.0

y_train = to_categorical(y_train, 10)
y_test = to_categorical(y_test, 10)

# 3. Cr√©er mod√®le CNN
model = Sequential([
    # Block 1
    Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(32, 32, 3)),
    BatchNormalization(),
    Conv2D(32, (3, 3), activation='relu', padding='same'),
    BatchNormalization(),
    MaxPooling2D((2, 2)),
    Dropout(0.25),

    # Block 2
    Conv2D(64, (3, 3), activation='relu', padding='same'),
    BatchNormalization(),
    Conv2D(64, (3, 3), activation='relu', padding='same'),
    BatchNormalization(),
    MaxPooling2D((2, 2)),
    Dropout(0.25),

    # Block 3
    Conv2D(128, (3, 3), activation='relu', padding='same'),
    BatchNormalization(),
    Conv2D(128, (3, 3), activation='relu', padding='same'),
    BatchNormalization(),
    MaxPooling2D((2, 2)),
    Dropout(0.25),

    # Classifier
    Flatten(),
    Dense(512, activation='relu'),
    BatchNormalization(),
    Dropout(0.5),
    Dense(10, activation='softmax')
])

print(model.summary())

# 4. Compiler
model.compile(
    optimizer='adam',
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

# 5. Callbacks
callbacks = [
    EarlyStopping(monitor='val_accuracy', patience=10, restore_best_weights=True),
    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-7)
]

# 6. Entra√Æner
history = model.fit(
    X_train, y_train,
    validation_split=0.1,
    epochs=50,
    batch_size=128,
    callbacks=callbacks,
    verbose=1
)

# 7. √âvaluer
test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)
print(f"\nTest Accuracy: {test_acc:.4f}")

# 8. Visualiser apprentissage
plt.figure(figsize=(14, 5))

plt.subplot(1, 2, 1)
plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Val Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.title('Loss Evolution')
plt.legend()
plt.grid(True, alpha=0.3)

plt.subplot(1, 2, 2)
plt.plot(history.history['accuracy'], label='Train Accuracy')
plt.plot(history.history['val_accuracy'], label='Val Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.title('Accuracy Evolution')
plt.legend()
plt.grid(True, alpha=0.3)

plt.tight_layout()
plt.show()

# 9. Pr√©dictions
predictions = model.predict(X_test[:20])
predicted_classes = np.argmax(predictions, axis=1)
true_classes = np.argmax(y_test[:20], axis=1)

# Afficher
plt.figure(figsize=(15, 6))
for i in range(20):
    plt.subplot(4, 5, i+1)
    plt.imshow(X_test[i])
    color = 'green' if predicted_classes[i] == true_classes[i] else 'red'
    plt.title(f'P: {class_names[predicted_classes[i]]}\nT: {class_names[true_classes[i]]}',
              color=color, fontsize=8)
    plt.axis('off')
plt.tight_layout()
plt.show()
```

---

## R√©sum√©

### Points Cl√©s

#### Op√©rations Fondamentales

| Op√©ration       | R√¥le                      | Param√®tres               |
| --------------- | ------------------------- | ------------------------ |
| **Convolution** | Extraction de features    | Filtres, stride, padding |
| **Activation**  | Non-lin√©arit√©             | ReLU g√©n√©ralement        |
| **Pooling**     | R√©duction dimensionnalit√© | Max ou Average           |

#### Architecture Typique

```
Input ‚Üí [Conv-ReLU-Conv-ReLU-Pool]√óN ‚Üí Flatten ‚Üí Dense ‚Üí Output
```

#### Architectures C√©l√®bres

| Mod√®le    | Innovation              | Ann√©e |
| --------- | ----------------------- | ----- |
| LeNet-5   | Premi√®re CNN            | 1998  |
| AlexNet   | ReLU, Dropout, GPU      | 2012  |
| VGG       | Profondeur, 3√ó3 filtres | 2014  |
| ResNet    | Skip connections        | 2015  |
| Inception | Multi-√©chelle           | 2014  |

#### Transfer Learning

**Strat√©gies** :

1. **Feature Extractor** : Geler base, entra√Æner classifier
2. **Fine-Tuning** : D√©geler derni√®res couches, LR faible

**Avantages** :

- Moins de donn√©es
- Convergence rapide
- Meilleures performances

### Code Type CNN

```python
model = Sequential([
    Conv2D(32, (3,3), activation='relu', padding='same', input_shape=(H,W,C)),
    BatchNormalization(),
    Conv2D(32, (3,3), activation='relu', padding='same'),
    MaxPooling2D((2,2)),
    Dropout(0.25),

    Conv2D(64, (3,3), activation='relu', padding='same'),
    Conv2D(64, (3,3), activation='relu', padding='same'),
    MaxPooling2D((2,2)),
    Dropout(0.25),

    Flatten(),
    Dense(128, activation='relu'),
    Dropout(0.5),
    Dense(num_classes, activation='softmax')
])
```

### Bonnes Pratiques

- [ ] Normaliser images (0-1 ou standardiser)
- [ ] Data augmentation pour √©viter overfitting
- [ ] BatchNormalization apr√®s Conv2D
- [ ] Dropout avant couches denses
- [ ] MaxPooling pour r√©duire dimensions
- [ ] Transfer learning si dataset petit
- [ ] Learning rate scheduling
- [ ] Early stopping sur validation

### Prochaine √âtape

**Module 9 : Apprentissage Non Supervis√©** - Clustering, PCA, autoencodeurs

---

**Navigation :**

- [‚¨ÖÔ∏è Module 7 : R√©seaux de Neurones Profonds](07_Reseaux_Neurones_Profonds.md)
- [üè† Retour au Sommaire](README.md)
- [‚û°Ô∏è Module 9 : Apprentissage Non Supervis√©](09_Apprentissage_Non_Supervise.md)
