"""
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
TUTORIEL COMPLET : CLASSIFICATION - LOGISTIC REGRESSION & DECISION TREE
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ¯ CAS D'USAGE RÃ‰EL : PrÃ©diction de Risque de CrÃ©dit Bancaire

CONTEXTE :
Une banque veut automatiser l'Ã©valuation du risque de dÃ©faut de paiement.
DonnÃ©es : historique de clients avec leurs caractÃ©ristiques et statut de remboursement.
Objectif : PrÃ©dire si un nouveau client va rembourser (0) ou faire dÃ©faut (1).

Ce tutoriel couvre :
1. POURQUOI et QUAND utiliser chaque modÃ¨le
2. PrÃ©paration des donnÃ©es avec explications des observations
3. Logistic Regression (quand/pourquoi ?)
4. Decision Tree (quand/pourquoi ?)
5. Comparaison et choix du meilleur modÃ¨le
6. Diagnostic : que signifient les mÃ©triques ?
7. Analyse des erreurs et conclusions

Chaque Ã©tape explique CE QU'IL FAUT OBSERVER et LES CONCLUSIONS Ã  en tirer.
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.datasets import make_classification
from sklearn.model_selection import train_test_split, cross_val_score, learning_curve
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier, plot_tree
from sklearn.metrics import (
    accuracy_score, precision_score, recall_score, f1_score,
    confusion_matrix, classification_report, roc_auc_score, roc_curve
)
import warnings
warnings.filterwarnings('ignore')

# Configuration
sns.set_style("whitegrid")
plt.rcParams['figure.figsize'] = (12, 6)

print("="*80)
print("TUTORIEL : CLASSIFICATION - PRÃ‰DICTION DE RISQUE DE CRÃ‰DIT")
print("="*80)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# PARTIE 1 : COMPRENDRE LE PROBLÃˆME ET CHOISIR LE BON MODÃˆLE
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

print("\n" + "="*80)
print("PARTIE 1 : QUAND UTILISER QUEL MODÃˆLE DE CLASSIFICATION ?")
print("="*80)

print("""
ğŸ¯ CONTEXTE DU PROBLÃˆME
-----------------------
Type : CLASSIFICATION BINAIRE
- Classe 0 : Client va rembourser (BON client)
- Classe 1 : Client va faire dÃ©faut (MAUVAIS client)

âš ï¸  IMPORTANCE DES ERREURS :
- Faux Positif (prÃ©dire dÃ©faut alors que bon) â†’ Client refusÃ© Ã  tort â†’ Perte de business
- Faux NÃ©gatif (prÃ©dire bon alors que dÃ©faut) â†’ PrÃªt non remboursÃ© â†’ Perte financiÃ¨re

ğŸ’¡ Dans ce cas : Faux NÃ©gatif plus grave que Faux Positif
   â†’ Nous allons privilÃ©gier le RECALL (minimiser faux nÃ©gatifs)

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ“Š TABLEAU DE DÃ‰CISION : QUEL MODÃˆLE CHOISIR ?
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

1ï¸âƒ£  LOGISTIC REGRESSION
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
âœ… UTILISER QUAND :
   - Relation linÃ©aire entre features et log-odds de la classe
   - Besoin d'INTERPRÃ‰TABILITÃ‰ (expliquer pourquoi client refusÃ©)
   - Besoin de PROBABILITÃ‰S calibrÃ©es
   - Baseline rapide
   - RÃ©glementation stricte (banque, santÃ©) â†’ besoin d'expliquer dÃ©cisions

âŒ NE PAS UTILISER QUAND :
   - Relations fortement non-linÃ©aires
   - Interactions complexes entre features
   - Features hautement corrÃ©lÃ©es sans rÃ©gularisation

ğŸ“ FORMULE :
   P(y=1|X) = 1 / (1 + e^-(Î²â‚€ + Î²â‚Xâ‚ + ... + Î²â‚™Xâ‚™))

ğŸ’¼ CAS D'USAGE TYPIQUES :
   - Scoring de crÃ©dit (notre cas !)
   - Diagnostic mÃ©dical
   - Email spam/non-spam
   - Churn prediction


2ï¸âƒ£  DECISION TREE
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
âœ… UTILISER QUAND :
   - Relations non-linÃ©aires
   - Interactions complexes entre features
   - Besoin de VISUALISATION des rÃ¨gles de dÃ©cision
   - Pas besoin de normalisation
   - Features catÃ©gorielles et numÃ©riques mÃ©langÃ©es

âŒ NE PAS UTILISER QUAND :
   - DonnÃ©es bruitÃ©es (OVERFITTING facile !)
   - Besoin de stabilitÃ© (petit changement â†’ arbre diffÃ©rent)
   - Seul (prÃ©fÃ©rer Random Forest pour production)

ğŸ“ PRINCIPE :
   Partitionne l'espace des features par seuils successifs
   Ex: "Si revenu > 50k ET Ã¢ge > 30 ALORS bon client"

ğŸ’¼ CAS D'USAGE TYPIQUES :
   - SystÃ¨mes experts mÃ©dicaux
   - Aide Ã  la dÃ©cision (rÃ¨gles explicites)
   - Prototypage rapide


3ï¸âƒ£  COMPARAISON RAPIDE
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  CritÃ¨re         â”‚  Logistic Reg       â”‚  Decision Tree       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ InterprÃ©tabilitÃ© â”‚ â˜…â˜…â˜…â˜…â˜… (coeff.)      â”‚ â˜…â˜…â˜…â˜…â˜† (rÃ¨gles)      â”‚
â”‚ Performance      â”‚ â˜…â˜…â˜…â˜†â˜†               â”‚ â˜…â˜…â˜…â˜…â˜†                â”‚
â”‚ Vitesse          â”‚ â˜…â˜…â˜…â˜…â˜…               â”‚ â˜…â˜…â˜…â˜…â˜†                â”‚
â”‚ Overfitting      â”‚ â˜…â˜…â˜…â˜…â˜† (rare)       â”‚ â˜…â˜…â˜†â˜†â˜† (frÃ©quent)    â”‚
â”‚ Non-linÃ©aritÃ©    â”‚ â˜…â˜†â˜†â˜†â˜†               â”‚ â˜…â˜…â˜…â˜…â˜…                â”‚
â”‚ Robustesse       â”‚ â˜…â˜…â˜…â˜…â˜†               â”‚ â˜…â˜…â˜†â˜†â˜†                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ğŸ¯ RECOMMANDATION POUR NOTRE CAS (CRÃ‰DIT BANCAIRE) :
   1. Commencer par Logistic Regression (interprÃ©tabilitÃ© + rÃ©glementation)
   2. Comparer avec Decision Tree
   3. En production : utiliser Random Forest ou XGBoost (meilleure performance)
""")

input("\nâ–¶ Appuyez sur EntrÃ©e pour continuer...")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# PARTIE 2 : GÃ‰NÃ‰RATION ET EXPLORATION DES DONNÃ‰ES
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

print("\n" + "="*80)
print("PARTIE 2 : DONNÃ‰ES ET EXPLORATION")
print("="*80)

# 2.1 GÃ©nÃ©rer des donnÃ©es rÃ©alistes
print("\nğŸ“Š GÃ©nÃ©ration de donnÃ©es synthÃ©tiques (simulant clients bancaires)...\n")

# make_classification : CrÃ©e un problÃ¨me de classification
# - n_samples : nombre de clients
# - n_features : nombre total de features
# - n_informative : features rÃ©ellement prÃ©dictives
# - n_redundant : features corrÃ©lÃ©es aux informatives (bruit rÃ©aliste)
# - n_classes : nombre de classes (2 = binaire)
# - weights : proportion des classes [classe 0, classe 1]
#   weights=[0.8, 0.2] â†’ 80% classe 0, 20% classe 1 (dÃ©sÃ©quilibrÃ©, rÃ©aliste pour crÃ©dit)
# - flip_y : pourcentage de labels alÃ©atoirement inversÃ©s (bruit)
# - random_state : reproductibilitÃ©
X, y = make_classification(
    n_samples=1000,
    n_features=10,
    n_informative=7,
    n_redundant=2,
    n_classes=2,
    weights=[0.8, 0.2],  # 80% bons clients, 20% dÃ©faut (rÃ©aliste)
    flip_y=0.05,  # 5% d'erreur dans les labels (bruit rÃ©aliste)
    random_state=42
)

print(f"âœ“ DonnÃ©es gÃ©nÃ©rÃ©es : {X.shape[0]} clients Ã— {X.shape[1]} features")
print(f"âœ“ Classes : {np.bincount(y)}")
print(f"  - Classe 0 (BON client) : {np.bincount(y)[0]} ({np.bincount(y)[0]/len(y)*100:.1f}%)")
print(f"  - Classe 1 (DÃ‰FAUT) : {np.bincount(y)[1]} ({np.bincount(y)[1]/len(y)*100:.1f}%)")

print(f"""
ğŸ” OBSERVATION #1 : Distribution des classes
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Classes DÃ‰SÃ‰QUILIBRÃ‰ES : {np.bincount(y)[0]/len(y)*100:.1f}% vs {np.bincount(y)[1]/len(y)*100:.1f}%

ğŸ’¡ CONCLUSION :
   C'est RÃ‰ALISTE pour un problÃ¨me de crÃ©dit (majoritÃ© de bons clients).

âš ï¸  CONSÃ‰QUENCE :
   - Un modÃ¨le naÃ¯f qui prÃ©dit toujours "0" aurait {np.bincount(y)[0]/len(y)*100:.1f}% d'accuracy !
   - Accuracy seule est TROMPEUSE sur classes dÃ©sÃ©quilibrÃ©es
   - PrivilÃ©gier : F1-Score, ROC-AUC, Precision/Recall

âœ… ACTION :
   - Utiliser stratify=y dans train_test_split
   - ConsidÃ©rer class_weight='balanced' dans les modÃ¨les
   - Ã‰valuer avec plusieurs mÃ©triques
""")

# CrÃ©er DataFrame avec noms de features rÃ©alistes
feature_names = [
    'Revenu', 'Age', 'Anciennete_Emploi', 'Montant_Credit',
    'Taux_Endettement', 'Nb_Credits_Actifs', 'Historique_Paiement',
    'Epargne', 'Valeur_Patrimoine', 'Nb_Dependants'
]
df = pd.DataFrame(X, columns=feature_names)
df['Defaut'] = y

print("\nğŸ“ˆ AperÃ§u des donnÃ©es :")
print(df.head(10))

print("\nğŸ“‰ Statistiques descriptives :")
print(df.describe())

# 2.2 Visualisation des distributions
print("\nğŸ“Š Analyse des distributions par classe...")

fig, axes = plt.subplots(2, 5, figsize=(20, 8))
axes = axes.ravel()

for i, col in enumerate(feature_names):
    axes[i].hist(df[df['Defaut'] == 0][col], bins=30, alpha=0.6,
                 label='BON (0)', edgecolor='black', color='green')
    axes[i].hist(df[df['Defaut'] == 1][col], bins=30, alpha=0.6,
                 label='DÃ‰FAUT (1)', edgecolor='black', color='red')
    axes[i].set_title(col)
    axes[i].set_xlabel('Valeur')
    axes[i].set_ylabel('FrÃ©quence')
    axes[i].legend()
    axes[i].grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig('e:/Nicolas/MIAGE/M2/BigData/FORMATION_ML/TUTORIELS/classification_distributions.png', dpi=100)
plt.show()

print("\nâœ“ Graphique sauvegardÃ© : classification_distributions.png")

print(f"""
ğŸ” OBSERVATION #2 : SÃ©parabilitÃ© des classes
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Regardez les histogrammes ci-dessus.

CE QU'IL FAUT OBSERVER :
1. Y a-t-il des features oÃ¹ les distributions des 2 classes sont bien sÃ©parÃ©es ?
   â†’ Ces features sont PRÃ‰DICTIVES

2. Y a-t-il des features oÃ¹ les distributions se chevauchent totalement ?
   â†’ Ces features sont PEU INFORMATIVES

3. Les distributions sont-elles linÃ©airement sÃ©parables ou complexes ?
   â†’ LinÃ©aire â†’ Logistic Regression suffira
   â†’ Complexe â†’ Decision Tree ou modÃ¨les non-linÃ©aires

ğŸ’¡ CONCLUSION ATTENDUE :
   Si make_classification a fait son travail, certaines features montrent
   une bonne sÃ©paration â†’ le problÃ¨me est RÃ‰SOLUBLE par ML.
""")

# 2.3 Matrice de corrÃ©lation
print("\nğŸ”— Analyse des corrÃ©lations...")

correlation_matrix = df.corr()

plt.figure(figsize=(12, 10))
sns.heatmap(correlation_matrix, annot=True, fmt='.2f', cmap='coolwarm',
            square=True, linewidths=0.5, center=0, cbar_kws={'label': 'CorrÃ©lation'})
plt.title('Matrice de CorrÃ©lation')
plt.tight_layout()
plt.savefig('e:/Nicolas/MIAGE/M2/BigData/FORMATION_ML/TUTORIELS/classification_correlation.png', dpi=100)
plt.show()

print("\nâœ“ Graphique sauvegardÃ© : classification_correlation.png")

print("\nCorrÃ©lations avec la cible (Defaut) :")
target_corr = correlation_matrix['Defaut'].sort_values(ascending=False)
print(target_corr)

print(f"""
ğŸ” OBSERVATION #3 : CorrÃ©lations
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
CE QU'IL FAUT OBSERVER :
1. CorrÃ©lation avec la cible (Defaut) :
   - |corr| > 0.3 : Feature FORTEMENT prÃ©dictive
   - |corr| 0.1-0.3 : Feature MODÃ‰RÃ‰MENT prÃ©dictive
   - |corr| < 0.1 : Feature PEU prÃ©dictive

2. CorrÃ©lations entre features (multicolinÃ©aritÃ©) :
   - |corr| > 0.8 entre 2 features : MULTICOLINÃ‰ARITÃ‰

ğŸ’¡ CONCLUSIONS :
   - Features les plus corrÃ©lÃ©es avec Defaut = features les plus importantes
   - MulticolinÃ©aritÃ© â†’ peut affecter Logistic Regression (coefficients instables)
   - MulticolinÃ©aritÃ© â†’ PAS de problÃ¨me pour Decision Tree

âœ… ACTIONS POSSIBLES :
   - Garder seulement les features les plus corrÃ©lÃ©es (feature selection)
   - Utiliser rÃ©gularisation L1/L2 pour Logistic Regression
   - Ou utiliser PCA pour rÃ©duire multicolinÃ©aritÃ©
""")

input("\nâ–¶ Appuyez sur EntrÃ©e pour continuer...")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# PARTIE 3 : PRÃ‰PARATION DES DONNÃ‰ES
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

print("\n" + "="*80)
print("PARTIE 3 : PRÃ‰PARATION DES DONNÃ‰ES")
print("="*80)

# 3.1 Division des donnÃ©es
print("\nâœ‚ï¸  Division des donnÃ©es...\n")

# stratify=y : CRUCIAL pour classes dÃ©sÃ©quilibrÃ©es
# Assure que train, val, test ont la mÃªme distribution des classes
X_train, X_temp, y_train, y_temp = train_test_split(
    X, y, test_size=0.3, random_state=42, stratify=y
)
X_val, X_test, y_val, y_test = train_test_split(
    X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp
)

print(f"âœ“ Train set : {len(X_train)} clients")
print(f"  - Classe 0 : {np.bincount(y_train)[0]} ({np.bincount(y_train)[0]/len(y_train)*100:.1f}%)")
print(f"  - Classe 1 : {np.bincount(y_train)[1]} ({np.bincount(y_train)[1]/len(y_train)*100:.1f}%)")

print(f"\nâœ“ Val set : {len(X_val)} clients")
print(f"  - Classe 0 : {np.bincount(y_val)[0]} ({np.bincount(y_val)[0]/len(y_val)*100:.1f}%)")
print(f"  - Classe 1 : {np.bincount(y_val)[1]} ({np.bincount(y_val)[1]/len(y_val)*100:.1f}%)")

print(f"\nâœ“ Test set : {len(X_test)} clients")
print(f"  - Classe 0 : {np.bincount(y_test)[0]} ({np.bincount(y_test)[0]/len(y_test)*100:.1f}%)")
print(f"  - Classe 1 : {np.bincount(y_test)[1]} ({np.bincount(y_test)[1]/len(y_test)*100:.1f}%)")

print(f"""
ğŸ” OBSERVATION #4 : Stratification
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Les proportions sont identiques dans train/val/test grÃ¢ce Ã  stratify=y.

ğŸ’¡ CONCLUSION :
   Sans stratify, on pourrait avoir par malchance un test set avec
   trÃ¨s peu de classe 1 â†’ Ã©valuation non reprÃ©sentative.
""")

# 3.2 Normalisation
print("\nâš–ï¸  Normalisation (IMPORTANTE pour Logistic Regression)...\n")

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_val_scaled = scaler.transform(X_val)
X_test_scaled = scaler.transform(X_test)

print("âœ“ DonnÃ©es normalisÃ©es")
print(f"  Moyenne (train) : {X_train_scaled.mean():.4f}")
print(f"  Std (train) : {X_train_scaled.std():.4f}")

print(f"""
â“ POURQUOI NORMALISER ?
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
1. Logistic Regression : features sur Ã©chelles diffÃ©rentes â†’ coefficients biaisÃ©s
   Ex: Revenu (0-100k) vs Age (18-80) â†’ Revenu domine artificiellement

2. Decision Tree : PAS NÃ‰CESSAIRE (splits basÃ©s sur seuils, pas magnitudes)
   Mais on normalise quand mÃªme pour comparaison Ã©quitable.

ğŸ’¡ CONCLUSION :
   Toujours normaliser pour modÃ¨les basÃ©s sur distances/gradients.
   (Logistic Reg, SVM, Neural Networks, KNN)
""")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# PARTIE 4 : BASELINE
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

print("\n" + "="*80)
print("PARTIE 4 : BASELINE (ModÃ¨le NaÃ¯f)")
print("="*80)

from sklearn.dummy import DummyClassifier

print("""
â“ POURQUOI UNE BASELINE ?
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Avant de construire un modÃ¨le complexe, Ã©tablir un point de rÃ©fÃ©rence.
Si notre modÃ¨le ne bat pas la baseline â†’ PROBLÃˆME !
""")

# StratÃ©gie 1 : Toujours prÃ©dire la classe majoritaire
baseline_majority = DummyClassifier(strategy='most_frequent')
baseline_majority.fit(X_train_scaled, y_train)
y_val_pred_baseline = baseline_majority.predict(X_val_scaled)

acc_baseline = accuracy_score(y_val, y_val_pred_baseline)
f1_baseline = f1_score(y_val, y_val_pred_baseline)

print(f"\nğŸ“Š BASELINE (prÃ©dire toujours classe {baseline_majority.classes_[np.argmax(baseline_majority.class_prior_)]})")
print(f"  Accuracy : {acc_baseline:.4f}")
print(f"  F1-Score : {f1_baseline:.4f}")

print(f"""
ğŸ” OBSERVATION #5 : Performance de la baseline
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Accuracy = {acc_baseline:.1%}

CE QUE CELA SIGNIFIE :
Un modÃ¨le stupide qui prÃ©dit toujours "BON client" a dÃ©jÃ  {acc_baseline:.1%} de bonnes rÃ©ponses !

ğŸ’¡ CONCLUSIONS :
   1. Accuracy seule est TROMPEUSE sur classes dÃ©sÃ©quilibrÃ©es
   2. F1-Score = {f1_baseline:.4f} â†’ trÃ¨s faible car Recall = 0 pour classe minoritaire
   3. Notre modÃ¨le doit avoir F1 >> {f1_baseline:.4f} pour Ãªtre utile
   4. ROC-AUC doit Ãªtre >> 0.5 (hasard)

ğŸ¯ OBJECTIF :
   Battre la baseline sur toutes les mÃ©triques, surtout F1 et ROC-AUC.
""")

input("\nâ–¶ Appuyez sur EntrÃ©e pour continuer...")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# PARTIE 5 : LOGISTIC REGRESSION
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

print("\n" + "="*80)
print("PARTIE 5 : LOGISTIC REGRESSION")
print("="*80)

print("""
ğŸ¯ RAPPEL : POURQUOI LOGISTIC REGRESSION POUR CE CAS ?
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
âœ… Banques doivent JUSTIFIER leurs dÃ©cisions (rÃ©glementation)
âœ… Coefficients permettent d'expliquer : "RefusÃ© car revenu trop faible"
âœ… ProbabilitÃ©s calibrÃ©es utiles pour ajuster seuil de dÃ©cision
âœ… Rapide, stable, bien compris

ğŸ“ PRINCIPE :
   P(DÃ©faut=1 | features) = sigmoid(Î²â‚€ + Î²â‚Â·Xâ‚ + ... + Î²â‚™Â·Xâ‚™)

   Si P > 0.5 â†’ PrÃ©dire DÃ©faut (1)
   Si P < 0.5 â†’ PrÃ©dire Bon (0)
""")

# 5.1 EntraÃ®nement
print("\nğŸš€ EntraÃ®nement du modÃ¨le...\n")

# LogisticRegression : Classification linÃ©aire
# PARAMÃˆTRES IMPORTANTS :
# - penalty : Type de rÃ©gularisation ('l1', 'l2', 'elasticnet', None)
#   * 'l2' (Ridge) : rÃ©duit coefficients, gÃ¨re multicolinÃ©aritÃ©
#   * 'l1' (Lasso) : sÃ©lection de features (coefficients â†’ 0)
# - C : Inverse de la force de rÃ©gularisation (default=1.0)
#   * C petit â†’ forte rÃ©gularisation (coefficients petits)
#   * C grand â†’ faible rÃ©gularisation (risque overfitting)
# - class_weight : Gestion du dÃ©sÃ©quilibre des classes
#   * 'balanced' : pÃ©nalise plus les erreurs sur classe minoritaire
#   * None : traite toutes les erreurs pareil
# - solver : Algorithme d'optimisation
#   * 'lbfgs' : Bon pour la plupart des cas
#   * 'liblinear' : Bon pour petites donnÃ©es
#   * 'saga' : Supporte L1, rapide sur grandes donnÃ©es
# - max_iter : Nombre max d'itÃ©rations pour convergence

# ModÃ¨le sans class_weight (pour comparaison)
model_lr = LogisticRegression(
    penalty='l2',
    C=1.0,
    max_iter=1000,
    random_state=42
)
model_lr.fit(X_train_scaled, y_train)

# ModÃ¨le avec class_weight='balanced' (recommandÃ© pour classes dÃ©sÃ©quilibrÃ©es)
model_lr_balanced = LogisticRegression(
    penalty='l2',
    C=1.0,
    class_weight='balanced',  # IMPORTANT pour dÃ©sÃ©quilibre
    max_iter=1000,
    random_state=42
)
model_lr_balanced.fit(X_train_scaled, y_train)

print("âœ“ ModÃ¨les entraÃ®nÃ©s")
print("  - Logistic Regression (standard)")
print("  - Logistic Regression (class_weight='balanced')")

# 5.2 PrÃ©dictions
y_val_pred_lr = model_lr.predict(X_val_scaled)
y_val_pred_lr_balanced = model_lr_balanced.predict(X_val_scaled)

# ProbabilitÃ©s (utile pour ROC-AUC et ajuster seuil)
y_val_proba_lr = model_lr.predict_proba(X_val_scaled)[:, 1]
y_val_proba_lr_balanced = model_lr_balanced.predict_proba(X_val_scaled)[:, 1]

# 5.3 Ã‰valuation
print("\nğŸ“Š Ã‰VALUATION\n")

def evaluate_classification(y_true, y_pred, y_proba, model_name):
    """Ã‰valuation complÃ¨te avec explications"""
    acc = accuracy_score(y_true, y_pred)
    prec = precision_score(y_true, y_pred)
    rec = recall_score(y_true, y_pred)
    f1 = f1_score(y_true, y_pred)
    auc = roc_auc_score(y_true, y_proba)

    print(f"{model_name}")
    print("-" * 60)
    print(f"  Accuracy  : {acc:.4f}")
    print(f"  Precision : {prec:.4f}")
    print(f"  Recall    : {rec:.4f}")
    print(f"  F1-Score  : {f1:.4f}")
    print(f"  ROC-AUC   : {auc:.4f}")
    print()

    return acc, prec, rec, f1, auc

acc_lr, prec_lr, rec_lr, f1_lr, auc_lr = evaluate_classification(
    y_val, y_val_pred_lr, y_val_proba_lr, "Logistic Regression (standard)"
)

acc_lr_bal, prec_lr_bal, rec_lr_bal, f1_lr_bal, auc_lr_bal = evaluate_classification(
    y_val, y_val_pred_lr_balanced, y_val_proba_lr_balanced,
    "Logistic Regression (class_weight='balanced')"
)

print(f"""
ğŸ” OBSERVATION #6 : MÃ©triques de Classification
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
COMPRENDRE LES MÃ‰TRIQUES :

1. ACCURACY = (TP + TN) / Total
   â†’ % de prÃ©dictions correctes
   âš ï¸  TROMPEUR sur classes dÃ©sÃ©quilibrÃ©es !

2. PRECISION = TP / (TP + FP)
   â†’ Parmi ceux prÃ©dits "DÃ©faut", combien le sont vraiment ?
   ğŸ’¼ Important si coÃ»t d'enquÃªte est Ã©levÃ©

3. RECALL (SensibilitÃ©) = TP / (TP + FN)
   â†’ Parmi les vrais "DÃ©faut", combien sont dÃ©tectÃ©s ?
   ğŸ’¼ CRUCIAL pour notre cas (ne pas louper les mauvais clients !)

4. F1-SCORE = 2 * (Precision Ã— Recall) / (Precision + Recall)
   â†’ Moyenne harmonique de Precision et Recall
   ğŸ’¼ Bon compromis pour classes dÃ©sÃ©quilibrÃ©es

5. ROC-AUC = Aire sous courbe ROC
   â†’ CapacitÃ© Ã  sÃ©parer les classes (0.5=hasard, 1.0=parfait)
   ğŸ’¼ IndÃ©pendant du seuil de dÃ©cision

OBSERVATIONS ATTENDUES :

â€¢ ModÃ¨le standard :
  Recall = {rec_lr:.4f} â†’ Peut-Ãªtre FAIBLE (rate des dÃ©fauts)
  Precision = {prec_lr:.4f} â†’ Peut-Ãªtre Ã‰LEVÃ‰E

â€¢ ModÃ¨le balanced :
  Recall = {rec_lr_bal:.4f} â†’ Devrait Ãªtre PLUS Ã‰LEVÃ‰
  Precision = {prec_lr_bal:.4f} â†’ Peut-Ãªtre PLUS FAIBLE

ğŸ’¡ CONCLUSION :
   class_weight='balanced' amÃ©liore Recall au dÃ©triment de Precision.
   Pour risque crÃ©dit : Recall > Precision (ne pas louper dÃ©fauts)
   â†’ Choisir modÃ¨le balanced si Recall nettement meilleur.
""")

# 5.4 Matrice de confusion
print("\nğŸ“Š Matrices de Confusion...")

fig, axes = plt.subplots(1, 2, figsize=(14, 5))

cm_lr = confusion_matrix(y_val, y_val_pred_lr)
cm_lr_bal = confusion_matrix(y_val, y_val_pred_lr_balanced)

sns.heatmap(cm_lr, annot=True, fmt='d', cmap='Blues', ax=axes[0], cbar=False)
axes[0].set_title('Logistic Regression (standard)')
axes[0].set_xlabel('PrÃ©diction')
axes[0].set_ylabel('RÃ©alitÃ©')

sns.heatmap(cm_lr_bal, annot=True, fmt='d', cmap='Blues', ax=axes[1], cbar=False)
axes[1].set_title('Logistic Regression (balanced)')
axes[1].set_xlabel('PrÃ©diction')
axes[1].set_ylabel('RÃ©alitÃ©')

plt.tight_layout()
plt.savefig('e:/Nicolas/MIAGE/M2/BigData/FORMATION_ML/TUTORIELS/classification_confusion_lr.png', dpi=100)
plt.show()

print("\nâœ“ Graphique sauvegardÃ© : classification_confusion_lr.png")

print(f"""
ğŸ” OBSERVATION #7 : Matrice de Confusion
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
LECTURE DE LA MATRICE :

          PrÃ©dit 0  PrÃ©dit 1
RÃ©el 0  â”‚   TN    â”‚   FP    â”‚  â† Faux Positifs (client bon refusÃ©)
RÃ©el 1  â”‚   FN    â”‚   TP    â”‚  â† Faux NÃ©gatifs (dÃ©faut non dÃ©tectÃ©)

CE QU'IL FAUT OBSERVER :

1. ModÃ¨le standard :
   FN (bas-gauche) = {cm_lr[1, 0]} â†’ DÃ©fauts NON DÃ‰TECTÃ‰S
   FP (haut-droit) = {cm_lr[0, 1]} â†’ Bons clients REFUSÃ‰S

2. ModÃ¨le balanced :
   FN (bas-gauche) = {cm_lr_bal[1, 0]} â†’ Devrait Ãªtre PLUS PETIT
   FP (haut-droit) = {cm_lr_bal[0, 1]} â†’ Peut Ãªtre PLUS GRAND

ğŸ’¡ CONCLUSION :
   Le modÃ¨le balanced dÃ©tecte plus de dÃ©fauts (FN â†“) mais refuse plus
   de bons clients (FP â†‘). C'est un TRADE-OFF.

ğŸ¯ DÃ‰CISION BUSINESS :
   Quel coÃ»t est le plus grave ?
   - 1 dÃ©faut non dÃ©tectÃ© = perte de Xâ‚¬ (montant du prÃªt)
   - 1 bon client refusÃ© = perte de Yâ‚¬ (intÃ©rÃªts potentiels)

   Si X >> Y â†’ Choisir modÃ¨le balanced (minimiser FN)
   Si Y >> X â†’ Choisir modÃ¨le standard (minimiser FP)
""")

# 5.5 Courbe ROC
print("\nğŸ“Š Courbes ROC...")

fpr_lr, tpr_lr, _ = roc_curve(y_val, y_val_proba_lr)
fpr_lr_bal, tpr_lr_bal, _ = roc_curve(y_val, y_val_proba_lr_balanced)

plt.figure(figsize=(10, 6))
plt.plot(fpr_lr, tpr_lr, label=f'LR standard (AUC={auc_lr:.4f})', linewidth=2)
plt.plot(fpr_lr_bal, tpr_lr_bal, label=f'LR balanced (AUC={auc_lr_bal:.4f})', linewidth=2)
plt.plot([0, 1], [0, 1], 'k--', label='Hasard (AUC=0.5)', linewidth=1)
plt.xlabel('False Positive Rate (FPR)')
plt.ylabel('True Positive Rate (TPR = Recall)')
plt.title('Courbes ROC - Logistic Regression')
plt.legend()
plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.savefig('e:/Nicolas/MIAGE/M2/BigData/FORMATION_ML/TUTORIELS/classification_roc_lr.png', dpi=100)
plt.show()

print("\nâœ“ Graphique sauvegardÃ© : classification_roc_lr.png")

print(f"""
ğŸ” OBSERVATION #8 : Courbe ROC
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
INTERPRÃ‰TATION :

- Axe X (FPR) : Taux de Faux Positifs (bons clients refusÃ©s)
- Axe Y (TPR) : Taux de Vrais Positifs = Recall (dÃ©fauts dÃ©tectÃ©s)

CE QU'IL FAUT OBSERVER :

1. Courbe proche du coin supÃ©rieur gauche = BON modÃ¨le
   (TPR Ã©levÃ© avec FPR faible)

2. AUC (Aire sous courbe) :
   - AUC = 0.5 : ModÃ¨le au HASARD (ligne diagonale)
   - AUC = 0.7-0.8 : ModÃ¨le ACCEPTABLE
   - AUC = 0.8-0.9 : ModÃ¨le BON
   - AUC > 0.9 : ModÃ¨le EXCELLENT

3. Nos modÃ¨les :
   - LR standard : AUC = {auc_lr:.4f}
   - LR balanced : AUC = {auc_lr_bal:.4f}

ğŸ’¡ CONCLUSION :
   Si AUC â‰ˆ mÃªme pour les 2 modÃ¨les :
   â†’ class_weight n'affecte PAS la capacitÃ© de discrimination
   â†’ Il affecte juste le SEUIL de dÃ©cision par dÃ©faut

   On peut donc :
   1. EntraÃ®ner avec class_weight='balanced'
   2. Puis ajuster le seuil manuellement selon coÃ»ts business
""")

# 5.6 Importance des features (coefficients)
print("\nğŸ“Š Importance des Features (Coefficients)...")

coef_df = pd.DataFrame({
    'Feature': feature_names,
    'Coefficient': model_lr_balanced.coef_[0],
    'Abs_Coefficient': np.abs(model_lr_balanced.coef_[0])
})
coef_df = coef_df.sort_values('Abs_Coefficient', ascending=False)

print(coef_df)

plt.figure(figsize=(10, 6))
plt.barh(coef_df['Feature'], coef_df['Coefficient'])
plt.xlabel('Coefficient')
plt.title('Importance des Features - Logistic Regression')
plt.axvline(0, color='black', linestyle='-', linewidth=0.8)
plt.grid(True, alpha=0.3, axis='x')
plt.tight_layout()
plt.savefig('e:/Nicolas/MIAGE/M2/BigData/FORMATION_ML/TUTORIELS/classification_feature_importance_lr.png', dpi=100)
plt.show()

print("\nâœ“ Graphique sauvegardÃ© : classification_feature_importance_lr.png")

print(f"""
ğŸ” OBSERVATION #9 : Coefficients (Importance)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
INTERPRÃ‰TATION DES COEFFICIENTS :

1. Coefficient POSITIF â†’ Augmente probabilitÃ© de DÃ©faut
   Ex: "Taux_Endettement" positif â†’ Plus d'endettement â†’ Plus de risque

2. Coefficient NÃ‰GATIF â†’ Diminue probabilitÃ© de DÃ©faut
   Ex: "Revenu" nÃ©gatif â†’ Plus de revenu â†’ Moins de risque

3. |Coefficient| grand â†’ Feature IMPORTANTE
   |Coefficient| petit â†’ Feature PEU IMPORTANTE

ğŸ’¼ UTILITÃ‰ BUSINESS :
   "M. Dupont refusÃ© car :
   - Taux endettement Ã©levÃ© (coef = +{coef_df.iloc[0]['Coefficient']:.2f})
   - Revenu faible (coef = {[c for f, c in zip(feature_names, model_lr_balanced.coef_[0]) if 'Revenu' in f][0] if any('Revenu' in f for f in feature_names) else 'N/A'})"

   â†’ EXPLICATION RÃ‰GLEMENTAIRE possible !

âš ï¸  ATTENTION :
   Les coefficients supposent INDÃ‰PENDANCE des features.
   Si multicolinÃ©aritÃ© forte â†’ coefficients instables.
   Solution : RÃ©gularisation L1 ou L2.
""")

input("\nâ–¶ Appuyez sur EntrÃ©e pour continuer vers Decision Tree...")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# PARTIE 6 : DECISION TREE
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

print("\n" + "="*80)
print("PARTIE 6 : DECISION TREE")
print("="*80)

print("""
ğŸ¯ RAPPEL : POURQUOI DECISION TREE ?
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
âœ… Capture RELATIONS NON-LINÃ‰AIRES
âœ… Capture INTERACTIONS automatiquement (ex: "Si revenu < 30k ET Ã¢ge < 25")
âœ… VISUALISATION des rÃ¨gles de dÃ©cision
âœ… Pas besoin de normalisation
âœ… GÃ¨re features catÃ©gorielles nativement

âŒ MAIS : Risque Ã©levÃ© d'OVERFITTING

ğŸ“ PRINCIPE :
   Partitionne rÃ©cursivement l'espace des features.
   Ex:
   - Racine : "Revenu < 40k ?"
     - OUI : "Endettement > 50% ?" â†’ DÃ©faut
     - NON : "Age < 25 ?" â†’ ...
""")

# 6.1 EntraÃ®nement
print("\nğŸš€ EntraÃ®nement des modÃ¨les...\n")

# DecisionTreeClassifier : Arbre de dÃ©cision
# PARAMÃˆTRES CRITIQUES POUR Ã‰VITER OVERFITTING :
# - max_depth : Profondeur maximale de l'arbre
#   * None : Pas de limite (DANGER overfitting !)
#   * 3-5 : Arbre simple (peut underfitter)
#   * 10-20 : Compromis
# - min_samples_split : Nb min d'Ã©chantillons pour split
#   * 2 (default) : Split agressif (overfitting)
#   * 20-50 : Plus conservateur
# - min_samples_leaf : Nb min d'Ã©chantillons dans feuille
#   * 1 (default) : Feuilles trÃ¨s spÃ©cifiques (overfitting)
#   * 10-20 : Feuilles plus gÃ©nÃ©rales
# - criterion : Mesure de qualitÃ© du split
#   * 'gini' : ImpuretÃ© de Gini (default, rapide)
#   * 'entropy' : Gain d'information (plus lent)
# - class_weight : Gestion dÃ©sÃ©quilibre
#   * 'balanced' : PÃ©nalise erreurs classe minoritaire

# Arbre sans contraintes (pour voir overfitting)
model_tree_overfit = DecisionTreeClassifier(
    random_state=42
)
model_tree_overfit.fit(X_train_scaled, y_train)

# Arbre avec contraintes (recommandÃ©)
model_tree = DecisionTreeClassifier(
    max_depth=5,
    min_samples_split=20,
    min_samples_leaf=10,
    class_weight='balanced',
    random_state=42
)
model_tree.fit(X_train_scaled, y_train)

print("âœ“ ModÃ¨les entraÃ®nÃ©s")
print("  - Decision Tree (overfitting)")
print("  - Decision Tree (avec contraintes)")

# 6.2 PrÃ©dictions
y_val_pred_tree_over = model_tree_overfit.predict(X_val_scaled)
y_val_pred_tree = model_tree.predict(X_val_scaled)

y_val_proba_tree_over = model_tree_overfit.predict_proba(X_val_scaled)[:, 1]
y_val_proba_tree = model_tree.predict_proba(X_val_scaled)[:, 1]

# 6.3 Ã‰valuation
print("\nğŸ“Š Ã‰VALUATION\n")

# Train scores (pour dÃ©tecter overfitting)
y_train_pred_tree_over = model_tree_overfit.predict(X_train_scaled)
y_train_pred_tree = model_tree.predict(X_train_scaled)

train_acc_over = accuracy_score(y_train, y_train_pred_tree_over)
train_acc = accuracy_score(y_train, y_train_pred_tree)

acc_tree_over, prec_tree_over, rec_tree_over, f1_tree_over, auc_tree_over = evaluate_classification(
    y_val, y_val_pred_tree_over, y_val_proba_tree_over,
    "Decision Tree (overfitting)"
)

acc_tree, prec_tree, rec_tree, f1_tree, auc_tree = evaluate_classification(
    y_val, y_val_pred_tree, y_val_proba_tree,
    "Decision Tree (avec contraintes)"
)

print(f"Train Accuracy (overfitting) : {train_acc_over:.4f}")
print(f"Val Accuracy (overfitting)   : {acc_tree_over:.4f}")
print(f"Ã‰cart (overfitting)          : {train_acc_over - acc_tree_over:.4f}\n")

print(f"Train Accuracy (contraintes) : {train_acc:.4f}")
print(f"Val Accuracy (contraintes)   : {acc_tree:.4f}")
print(f"Ã‰cart (contraintes)          : {train_acc - acc_tree:.4f}")

print(f"""
ğŸ” OBSERVATION #10 : Overfitting du Decision Tree
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
CE QU'IL FAUT OBSERVER :

Ã‰cart Train - Val :
- Overfitting : {train_acc_over - acc_tree_over:.4f}
- Contraintes : {train_acc - acc_tree:.4f}

ğŸ’¡ RÃˆGLE :
   Si Ã©cart > 0.05 â†’ OVERFITTING probable
   Si Ã©cart > 0.10 â†’ OVERFITTING FORT

OBSERVATIONS ATTENDUES :

1. Arbre sans contraintes :
   - Train Acc â‰ˆ 1.00 (apprend par cÅ“ur !)
   - Val Acc < Train (gÃ©nÃ©ralise mal)
   - Ã‰cart IMPORTANT â†’ OVERFITTING

2. Arbre avec contraintes :
   - Train Acc < 1.00 (n'apprend pas par cÅ“ur)
   - Val Acc â‰ˆ Train (gÃ©nÃ©ralise mieux)
   - Ã‰cart FAIBLE â†’ Bon Ã©quilibre

ğŸ’¡ CONCLUSION :
   Les contraintes (max_depth, min_samples_split, etc.) sont
   ESSENTIELLES pour Ã©viter overfitting avec Decision Tree.

   En production : Utiliser Random Forest (moyenne de trees)
   â†’ RÃ©duit overfitting naturellement.
""")

# 6.4 Visualisation de l'arbre
print("\nğŸ“Š Visualisation de l'arbre (limitÃ© Ã  profondeur 3 pour lisibilitÃ©)...")

plt.figure(figsize=(20, 10))
plot_tree(
    model_tree,
    max_depth=3,
    feature_names=feature_names,
    class_names=['BON', 'DÃ‰FAUT'],
    filled=True,
    fontsize=10
)
plt.title('Decision Tree (profondeur limitÃ©e Ã  3 pour visualisation)')
plt.tight_layout()
plt.savefig('e:/Nicolas/MIAGE/M2/BigData/FORMATION_ML/TUTORIELS/classification_tree.png', dpi=100)
plt.show()

print("\nâœ“ Graphique sauvegardÃ© : classification_tree.png")

print(f"""
ğŸ” OBSERVATION #11 : Structure de l'Arbre
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
LECTURE DE L'ARBRE :

1. NÅ“ud racine (en haut) : Premier split le plus important
   â†’ Feature la plus discriminante

2. Chaque nÅ“ud montre :
   - Condition de split
   - gini : ImpuretÃ© (0 = pur, 0.5 = 50/50)
   - samples : Nombre d'Ã©chantillons dans ce nÅ“ud
   - value : [nb classe 0, nb classe 1]
   - class : Classe majoritaire

3. Couleur :
   - Bleu foncÃ© : MajoritÃ© classe 0 (BON)
   - Orange foncÃ© : MajoritÃ© classe 1 (DÃ‰FAUT)
   - Couleur claire : Incertain (50/50)

ğŸ’¡ INTERPRÃ‰TATION BUSINESS :
   L'arbre crÃ©e des RÃˆGLES DE DÃ‰CISION explicites :

   "Si Revenu < 40k ET Endettement > 50% â†’ DÃ‰FAUT"

   â†’ Peut Ãªtre intÃ©grÃ© dans systÃ¨me expert
   â†’ Facile Ã  expliquer aux experts mÃ©tier

âš ï¸  LIMITES :
   - Arbre instable (petit changement donnÃ©es â†’ arbre diffÃ©rent)
   - Seuils discontinus (ex: 39.9k â†’ BON, 40.1k â†’ DÃ‰FAUT)
   - Peut manquer relations linÃ©aires simples
""")

# 6.5 Feature Importance
print("\nğŸ“Š Importance des Features (Decision Tree)...")

importance_df = pd.DataFrame({
    'Feature': feature_names,
    'Importance': model_tree.feature_importances_
})
importance_df = importance_df.sort_values('Importance', ascending=False)

print(importance_df)

fig, axes = plt.subplots(1, 2, figsize=(16, 6))

# Decision Tree importance
axes[0].barh(importance_df['Feature'], importance_df['Importance'], color='green', alpha=0.7)
axes[0].set_xlabel('Importance')
axes[0].set_title('Feature Importance - Decision Tree')
axes[0].grid(True, alpha=0.3, axis='x')

# Logistic Regression importance (pour comparaison)
axes[1].barh(coef_df['Feature'], coef_df['Abs_Coefficient'], color='blue', alpha=0.7)
axes[1].set_xlabel('|Coefficient|')
axes[1].set_title('Feature Importance - Logistic Regression')
axes[1].grid(True, alpha=0.3, axis='x')

plt.tight_layout()
plt.savefig('e:/Nicolas/MIAGE/M2/BigData/FORMATION_ML/TUTORIELS/classification_feature_importance_comparison.png', dpi=100)
plt.show()

print("\nâœ“ Graphique sauvegardÃ© : classification_feature_importance_comparison.png")

print(f"""
ğŸ” OBSERVATION #12 : Importance des Features (Tree vs LR)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
DIFFÃ‰RENCES POSSIBLES :

1. Decision Tree : Importance = rÃ©duction d'impuretÃ© cumulÃ©e
   â†’ Features utilisÃ©es tÃ´t dans l'arbre = importantes

2. Logistic Regression : |Coefficient| = impact linÃ©aire
   â†’ Features avec corrÃ©lation forte = importantes

CE QU'IL FAUT OBSERVER :

â€¢ Si rankings similaires â†’ Features vraiment importantes
  Accord entre modÃ¨les â†’ Confiance Ã©levÃ©e

â€¢ Si rankings trÃ¨s diffÃ©rents â†’ ModÃ¨les capturent aspects diffÃ©rents
  Ex: Tree trouve interactions, LR trouve effets linÃ©aires

ğŸ’¡ CONCLUSION :
   Features importantes dans LES DEUX modÃ¨les :
   â†’ Ce sont les features RÃ‰ELLEMENT prÃ©dictives
   â†’ Prioriser leur qualitÃ© (collecte, nettoyage)

   Features importantes seulement dans Tree :
   â†’ Interactions non-linÃ©aires possibles
   â†’ Peut crÃ©er nouvelles features (ex: Revenu Ã— Endettement)
""")

input("\nâ–¶ Appuyez sur EntrÃ©e pour voir la comparaison finale...")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# PARTIE 7 : COMPARAISON FINALE ET CHOIX DU MODÃˆLE
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

print("\n" + "="*80)
print("PARTIE 7 : COMPARAISON FINALE")
print("="*80)

# 7.1 Tableau rÃ©capitulatif
print("\nğŸ“Š TABLEAU RÃ‰CAPITULATIF DES PERFORMANCES\n")

results = pd.DataFrame({
    'ModÃ¨le': [
        'Baseline',
        'LR Standard',
        'LR Balanced',
        'Tree Overfit',
        'Tree Constrained'
    ],
    'Accuracy': [
        acc_baseline, acc_lr, acc_lr_bal, acc_tree_over, acc_tree
    ],
    'Precision': [
        0, prec_lr, prec_lr_bal, prec_tree_over, prec_tree
    ],
    'Recall': [
        0, rec_lr, rec_lr_bal, rec_tree_over, rec_tree
    ],
    'F1-Score': [
        f1_baseline, f1_lr, f1_lr_bal, f1_tree_over, f1_tree
    ],
    'ROC-AUC': [
        0.5, auc_lr, auc_lr_bal, auc_tree_over, auc_tree
    ]
})

print(results.to_string(index=False))

# Visualisation comparative
fig, axes = plt.subplots(2, 2, figsize=(14, 10))

metrics = ['Accuracy', 'Precision', 'Recall', 'F1-Score']
for idx, metric in enumerate(metrics):
    ax = axes[idx // 2, idx % 2]
    ax.bar(results['ModÃ¨le'], results[metric], alpha=0.7, edgecolor='black')
    ax.set_ylabel(metric)
    ax.set_title(f'Comparaison : {metric}')
    ax.tick_params(axis='x', rotation=45)
    ax.grid(True, alpha=0.3, axis='y')
    ax.set_ylim(0, 1)

plt.tight_layout()
plt.savefig('e:/Nicolas/MIAGE/M2/BigData/FORMATION_ML/TUTORIELS/classification_comparison.png', dpi=100)
plt.show()

print("\nâœ“ Graphique sauvegardÃ© : classification_comparison.png")

print(f"""
ğŸ” OBSERVATION FINALE : Quel modÃ¨le choisir ?
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ANALYSE MÃ‰TRIQUE PAR MÃ‰TRIQUE :

1. ACCURACY :
   {results.loc[results['Accuracy'].idxmax(), 'ModÃ¨le']} gagne avec {results['Accuracy'].max():.4f}
   âš ï¸  Mais rappel : peu fiable sur classes dÃ©sÃ©quilibrÃ©es

2. F1-SCORE (mÃ©trique clÃ©) :
   {results.loc[results['F1-Score'].idxmax(), 'ModÃ¨le']} gagne avec {results['F1-Score'].max():.4f}

3. RECALL (crucial pour dÃ©tecter dÃ©fauts) :
   {results.loc[results['Recall'].idxmax(), 'ModÃ¨le']} gagne avec {results['Recall'].max():.4f}

4. ROC-AUC (capacitÃ© de discrimination) :
   {results.loc[results['ROC-AUC'].idxmax(), 'ModÃ¨le']} gagne avec {results['ROC-AUC'].max():.4f}

""")

# Trouver le meilleur modÃ¨le
best_f1_model = results.loc[results['F1-Score'].idxmax(), 'ModÃ¨le']
best_auc_model = results.loc[results['ROC-AUC'].idxmax(), 'ModÃ¨le']

print(f"""
ğŸ¯ RECOMMANDATION FINALE
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Pour CRÃ‰DIT BANCAIRE :

1. PRIORITÃ‰ : Minimiser Faux NÃ©gatifs (dÃ©fauts non dÃ©tectÃ©s)
   â†’ PrivilÃ©gier RECALL

2. CONTRAINTE : Expliquer les dÃ©cisions (rÃ©glementation)
   â†’ Logistic Regression prÃ©fÃ©rable

3. TRADE-OFF : Recall vs Precision
   â†’ LR Balanced meilleur Ã©quilibre

ğŸ† CHOIX : {best_f1_model}
   F1-Score : {results.loc[results['ModÃ¨le'] == best_f1_model, 'F1-Score'].values[0]:.4f}
   Recall : {results.loc[results['ModÃ¨le'] == best_f1_model, 'Recall'].values[0]:.4f}
   ROC-AUC : {results.loc[results['ModÃ¨le'] == best_f1_model, 'ROC-AUC'].values[0]:.4f}

ğŸ’¼ EN PRODUCTION :
   Option A : Logistic Regression (interprÃ©tabilitÃ©, rÃ©glementation)
   Option B : Random Forest ou XGBoost (performance max)
   â†’ Compromis selon besoins mÃ©tier

ğŸ“‹ NEXT STEPS :
   1. Optimiser seuil de dÃ©cision selon coÃ»ts mÃ©tier
   2. Feature engineering (crÃ©er interactions)
   3. Tester Random Forest / XGBoost
   4. Cross-validation plus poussÃ©e
   5. Tester sur test set final
""")

# 7.2 Ã‰valuation sur test set
print("\n" + "="*80)
print("Ã‰VALUATION FINALE SUR TEST SET")
print("="*80)

# Choisir le meilleur modÃ¨le
if best_f1_model == 'LR Balanced':
    best_model = model_lr_balanced
    model_name = 'Logistic Regression (Balanced)'
elif best_f1_model == 'Tree Constrained':
    best_model = model_tree
    model_name = 'Decision Tree (Constrained)'
else:
    best_model = model_lr_balanced
    model_name = 'Logistic Regression (Balanced)'

y_test_pred = best_model.predict(X_test_scaled)
y_test_proba = best_model.predict_proba(X_test_scaled)[:, 1]

print(f"\nğŸ† ModÃ¨le sÃ©lectionnÃ© : {model_name}\n")

test_acc = accuracy_score(y_test, y_test_pred)
test_prec = precision_score(y_test, y_test_pred)
test_rec = recall_score(y_test, y_test_pred)
test_f1 = f1_score(y_test, y_test_pred)
test_auc = roc_auc_score(y_test, y_test_proba)

print("ğŸ“Š PERFORMANCE SUR TEST SET")
print("-" * 60)
print(f"Accuracy  : {test_acc:.4f}")
print(f"Precision : {test_prec:.4f}")
print(f"Recall    : {test_rec:.4f}")
print(f"F1-Score  : {test_f1:.4f}")
print(f"ROC-AUC   : {test_auc:.4f}")

print("\nğŸ“‹ Classification Report :")
print(classification_report(y_test, y_test_pred, target_names=['BON', 'DÃ‰FAUT']))

# Matrice de confusion finale
cm_test = confusion_matrix(y_test, y_test_pred)

plt.figure(figsize=(8, 6))
sns.heatmap(cm_test, annot=True, fmt='d', cmap='Blues', cbar=False)
plt.xlabel('PrÃ©diction')
plt.ylabel('RÃ©alitÃ©')
plt.title(f'Matrice de Confusion - Test Set\n{model_name}')
plt.tight_layout()
plt.savefig('e:/Nicolas/MIAGE/M2/BigData/FORMATION_ML/TUTORIELS/classification_confusion_final.png', dpi=100)
plt.show()

print("\nâœ“ Graphique sauvegardÃ© : classification_confusion_final.png")

print(f"""
ğŸ” OBSERVATION FINALE : Performance sur donnÃ©es jamais vues
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Le test set reprÃ©sente la VRAIE performance en production.

CE QU'IL FAUT OBSERVER :

1. Test â‰ˆ Val ? â†’ ModÃ¨le GÃ‰NÃ‰RALISE bien
2. Test << Val ? â†’ Peut-Ãªtre sur-optimisÃ© sur val (overfitting)
3. Test > Val ? â†’ Chanceux ou val set non reprÃ©sentatif

NOTRE CAS :
- F1 Test : {test_f1:.4f}
- F1 Val : {results.loc[results['ModÃ¨le'] == best_f1_model, 'F1-Score'].values[0]:.4f}
- Ã‰cart : {abs(test_f1 - results.loc[results['ModÃ¨le'] == best_f1_model, 'F1-Score'].values[0]):.4f}

ğŸ’¡ CONCLUSION :
   Si Ã©cart < 0.05 â†’ Performance STABLE â†’ PrÃªt pour production
   Si Ã©cart > 0.05 â†’ Revoir validation ou plus de donnÃ©es
""")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# PARTIE 8 : SAUVEGARDE ET UTILISATION
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

print("\n" + "="*80)
print("PARTIE 8 : SAUVEGARDE DU MODÃˆLE")
print("="*80)

import joblib

joblib.dump(best_model, 'e:/Nicolas/MIAGE/M2/BigData/FORMATION_ML/TUTORIELS/best_classification_model.pkl')
joblib.dump(scaler, 'e:/Nicolas/MIAGE/M2/BigData/FORMATION_ML/TUTORIELS/classification_scaler.pkl')

print("âœ“ ModÃ¨le sauvegardÃ© : best_classification_model.pkl")
print("âœ“ Scaler sauvegardÃ© : classification_scaler.pkl")

print(f"""
ğŸ“¦ UTILISATION EN PRODUCTION
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
```python
import joblib
import numpy as np

# Charger
model = joblib.load('best_classification_model.pkl')
scaler = joblib.load('classification_scaler.pkl')

# Nouveau client
nouveau_client = np.array([[
    50000,  # Revenu
    35,     # Age
    5,      # AnciennetÃ© emploi
    # ... autres features
]])

# Normaliser
nouveau_client_scaled = scaler.transform(nouveau_client)

# PrÃ©dire
prediction = model.predict(nouveau_client_scaled)[0]
probabilite = model.predict_proba(nouveau_client_scaled)[0, 1]

print(f"PrÃ©diction : {{'BON', 'DÃ‰FAUT'}}[prediction]")
print(f"ProbabilitÃ© de dÃ©faut : {{probabilite:.2%}}")

# DÃ©cision avec seuil personnalisÃ©
seuil = 0.3  # Ajuster selon coÃ»ts mÃ©tier
if probabilite > seuil:
    print("REFUSER le crÃ©dit")
else:
    print("ACCEPTER le crÃ©dit")
```
""")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# RÃ‰SUMÃ‰ ET LEÃ‡ONS APPRISES
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

print("\n" + "="*80)
print("ğŸ‰ RÃ‰SUMÃ‰ ET LEÃ‡ONS APPRISES")
print("="*80)

print(f"""
ğŸ“š CE QUE NOUS AVONS APPRIS
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

1ï¸âƒ£  CHOIX DU MODÃˆLE dÃ©pend du CONTEXTE :
   âœ… Logistic Regression : InterprÃ©tabilitÃ©, rÃ©glementation, baseline
   âœ… Decision Tree : Relations non-linÃ©aires, rÃ¨gles explicites
   âŒ Attention overfitting avec Decision Tree !

2ï¸âƒ£  CLASSES DÃ‰SÃ‰QUILIBRÃ‰ES :
   âš ï¸  Accuracy seule est TROMPEUSE
   âœ… Utiliser : F1-Score, ROC-AUC, Precision/Recall
   âœ… Stratifier train/val/test
   âœ… Utiliser class_weight='balanced'

3ï¸âƒ£  MÃ‰TRIQUES SELON CONTEXTE :
   ğŸ’¼ CrÃ©dit : PrivilÃ©gier RECALL (dÃ©tecter dÃ©fauts)
   ğŸ“§ Spam : PrivilÃ©gier PRECISION (pas de faux positifs)
   âš–ï¸  Ã‰quilibre : F1-Score

4ï¸âƒ£  OBSERVATIONS CLÃ‰S :
   ğŸ“Š Distributions : SÃ©parabilitÃ© des classes
   ğŸ”— CorrÃ©lations : Features prÃ©dictives
   ğŸ“‰ Matrice confusion : Types d'erreurs
   ğŸ“ˆ Courbe ROC : CapacitÃ© de discrimination
   ğŸŒ³ Arbre : RÃ¨gles de dÃ©cision
   ğŸ“Š Feature importance : Features critiques

5ï¸âƒ£  DIAGNOSTIC OVERFITTING :
   ğŸ” Train >> Val â†’ Overfitting
   âœ… Contraintes (max_depth, min_samples)
   âœ… RÃ©gularisation (L1, L2)
   âœ… Cross-validation

6ï¸âƒ£  BONNES PRATIQUES :
   âœ… Baseline d'abord
   âœ… Commencer simple (Logistic Reg)
   âœ… Comparer plusieurs modÃ¨les
   âœ… InterprÃ©ter les rÃ©sultats (pas juste optimiser)
   âœ… Penser MÃ‰TIER (coÃ»ts, contraintes)
   âœ… Test set UNE SEULE FOIS

ğŸ¯ PROCHAINES Ã‰TAPES
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
1. Tester Random Forest et XGBoost (meilleure performance)
2. Feature engineering avancÃ© (interactions, transformations)
3. Optimiser seuil de dÃ©cision selon coÃ»ts mÃ©tier
4. Cross-validation plus poussÃ©e (Stratified K-Fold)
5. Analyse d'erreurs approfondie (cas difficiles)
6. A/B testing en production

ğŸ’¡ RÃˆGLE D'OR
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
"Le meilleur modÃ¨le n'est PAS celui avec la meilleure mÃ©trique,
mais celui qui rÃ©sout le problÃ¨me MÃ‰TIER de la faÃ§on la plus FIABLE."

âœ… CHECKLIST CLASSIFICATION
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
âœ“ DonnÃ©es explorÃ©es (EDA)
âœ“ Classes Ã©quilibrÃ©es ou stratifiÃ©es
âœ“ Baseline Ã©tablie
âœ“ Plusieurs modÃ¨les testÃ©s
âœ“ MÃ©triques appropriÃ©es choisies
âœ“ Overfitting vÃ©rifiÃ©
âœ“ Feature importance analysÃ©e
âœ“ Test set Ã©valuÃ© UNE FOIS
âœ“ ModÃ¨le sauvegardÃ©
âœ“ DÃ©cision business prise
""")

print("="*80)
print("âœ¨ TUTORIEL TERMINÃ‰ AVEC SUCCÃˆS ! âœ¨")
print("="*80)
print("\nğŸš€ Vous maÃ®trisez maintenant la classification binaire !")
print("ğŸ“š Prochain tutoriel : Random Forest et XGBoost")
